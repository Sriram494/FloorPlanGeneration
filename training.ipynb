{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data wrangling\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import distinctipy\n",
    "from torch_geometric.utils import from_networkx\n",
    "\n",
    "# to show advance in for loops\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Using pytorch geometric\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch.utils.data import Dataset\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "\n",
    "# For the GNN model\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "# for my pc\n",
    "url_living_to_all = \"Planify_Graphs_Scaled/Planify_Graphs_Scaled/Graphs_living_to_all.pkl\"\n",
    "url_boundary = \"Planify_Graphs_Scaled/Planify_Graphs_Scaled/boundaries.pkl\"\n",
    "\n",
    "# # for kaggle\n",
    "# url_real = \"/kaggle/input/planify-graphs-all-forms/graphs/Graphs_real.pkl\"\n",
    "# url_boundary = \"/kaggle/input/planify-graphs-all-forms/graphs/boundaries.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoms_columns = ['inner', 'living', 'master', 'kitchen', 'bathroom', 'dining', 'child', 'study',\n",
    "                   'second_room', 'guest', 'balcony', 'storage', 'wall-in',\n",
    "                    'outer_wall', 'front', 'inner_wall', 'interior',\n",
    "                   'front_door', 'outer_wall', 'entrance']\n",
    "\n",
    "N = len(geoms_columns)\n",
    "colors = (np.array(distinctipy.get_colors(N)) * 255).astype(np.uint8)\n",
    "room_color = {room_name: colors[i] for i, room_name in enumerate(geoms_columns)}\n",
    "def draw_graph_nodes(G, living_to_all=False):\n",
    "    #  nodes positions for drawing, note that we invert the y pos\n",
    "    pos = {node: (G.nodes[node]['actualCentroid_x'], -G.nodes[node]['actualCentroid_y']) for node in G.nodes}\n",
    "    \n",
    "    scales = [G.nodes[node]['roomSize'] * 10000 for node in G] \n",
    "    color_map = [room_color[G.nodes[node]['roomType_name']]/255 for node in G]\n",
    "    edge_labels = nx.get_edge_attributes(G, 'distance')\n",
    "\n",
    "    \n",
    "    nx.draw_networkx_nodes(G, pos=pos, node_size=scales, node_color=color_map);\n",
    "    nx.draw_networkx_edges(G, pos=pos, edge_color='b');\n",
    "    nx.draw_networkx_labels(G, pos=pos, font_size=8);\n",
    "\n",
    "    if living_to_all:\n",
    "        nx.draw_networkx_edge_labels(G, pos=pos, edge_labels=edge_labels)\n",
    "\n",
    "    \n",
    "    # # Drawing the graph inside a good boundary.\n",
    "    # x_coords  = [pos[node][0] for node in pos]\n",
    "    # y_coords  = [pos[node][1] for node in pos]\n",
    "    # threshold = max(scales) / 100\n",
    "    \n",
    "    # plt.xlim(min(x_coords) - threshold, max(x_coords) + threshold)\n",
    "    plt.xlim(-10, 266)\n",
    "    plt.ylim(-266, 10)\n",
    "    \n",
    "\n",
    "def draw_graph_boundary(G):\n",
    "    #  nodes positions for drawing, note that we invert the y pos\n",
    "    pos = {node: (G.nodes[node]['centroid'][0], -G.nodes[node]['centroid'][1])  for node in G.nodes}\n",
    "    \n",
    "    door_color = '#90EE90'\n",
    "    other_nodes_color = '#0A2A5B'\n",
    "    color_map = [door_color if G.nodes[node]['type'] == 1 else other_nodes_color for node in G.nodes]\n",
    "    \n",
    "    # nx.draw(G, pos=pos, with_labels=True, node_color=color_map, font_color='w', font_size=12)\n",
    "    nx.draw_networkx_nodes(G, pos=pos, node_size=150, node_color=color_map);\n",
    "    nx.draw_networkx_edges(G, pos=pos)\n",
    "    \n",
    "    plt.xlim(-10, 266)\n",
    "    plt.ylim(-266, 10)\n",
    "    \n",
    "    \n",
    "# For statistics\n",
    "def get_max_min_x_y(graphs):\n",
    "    max_x = 0\n",
    "    max_y = 0\n",
    "    min_x = float('inf')\n",
    "    min_y = float('inf')\n",
    "    \n",
    "    for G in tqdm(graphs, desc=\"Getting maximum x, y\", total=len(graphs)):\n",
    "        max_x_in_graph = G.x.T[1].max().item()\n",
    "        max_y_in_graph = G.x.T[2].max().item()\n",
    "        \n",
    "        min_x_in_graph = G.x.T[1].min().item()\n",
    "        min_y_in_graph = G.x.T[2].min().item()\n",
    "        \n",
    "        if max_x_in_graph > max_x:\n",
    "            max_x = max_x_in_graph\n",
    "        if max_y_in_graph > max_y:\n",
    "            max_y = max_y_in_graph\n",
    "            \n",
    "        if min_x_in_graph < min_x:\n",
    "            min_x = min_x_in_graph\n",
    "        if min_y_in_graph < min_y:\n",
    "            min_y = min_y_in_graph\n",
    "            \n",
    "    values = {'max_x': max_x, 'max_y': max_y, 'min_x': min_x, 'min_y': min_y}\n",
    "    return values\n",
    "\n",
    "\n",
    "def get_all_x_y(graphs):\n",
    "    \"\"\"Get all values of x and y from all graphs\n",
    "        Input: list of graphs\n",
    "        Output: x and y as pandas series\n",
    "    \"\"\"\n",
    "    x = []\n",
    "    y = []\n",
    "    for i, G in tqdm(enumerate(graphs), desc=\"getting all Xs, Ys\", total=len(graphs)):\n",
    "        for i in range(len(G.x)):\n",
    "            x.append(G.x[i][1].item())\n",
    "            y.append(G.x[i][2].item())\n",
    "            \n",
    "\n",
    "    x = pd.Series(x)\n",
    "    y = pd.Series(y)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "def boxplot_centrValues(x, y):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Plot the boxplots\n",
    "    ax.boxplot([x, y])\n",
    "\n",
    "    # Set the xtick labels\n",
    "    ax.set_xticklabels(['x', 'y'])\n",
    "\n",
    "    # Add axis labels and title\n",
    "    ax.set_xlabel('Data')\n",
    "    ax.set_ylabel('Value')\n",
    "    ax.set_title('Boxplot of x and y in all graphs')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def plot_histograms(x, y):\n",
    "    x.hist(density=True, bins=100, alpha=0.6, label='x');\n",
    "    y.hist(density=True, bins=100, alpha=0.3, label='y');\n",
    "    plt.legend();\n",
    "    plt.title('Distribution of x and y');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 8 nodes and 7 edges\n"
     ]
    }
   ],
   "source": [
    "with open(url_living_to_all, 'rb') as f:\n",
    "    Graphs = pickle.load(f)\n",
    "    \n",
    "G = Graphs[1911]\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 9 nodes and 9 edges\n"
     ]
    }
   ],
   "source": [
    "with open(url_boundary, 'rb') as f:\n",
    "    boundaries = pickle.load(f)\n",
    "    \n",
    "b = boundaries[1911]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m     G_new \u001b[38;5;241m=\u001b[39m from_networkx(G, group_node_attrs\u001b[38;5;241m=\u001b[39mfeatures, group_edge_attrs\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m G_new\n\u001b[1;32m----> 8\u001b[0m Graphs_pyTorch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconvert_networkx_Graphs_to_pyTorchGraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mGraphs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m Graphs_pyTorch[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m, in \u001b[0;36mconvert_networkx_Graphs_to_pyTorchGraphs\u001b[1;34m(G)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_networkx_Graphs_to_pyTorchGraphs\u001b[39m(G):\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Converting networkx graphs to pytorchGeo graphs\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroomType_embd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactualCentroid_x\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactualCentroid_y\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def convert_networkx_Graphs_to_pyTorchGraphs(G):\n",
    "    \"\"\" Converting networkx graphs to pytorchGeo graphs\n",
    "    \"\"\"\n",
    "    features = ['roomType_embd', 'actualCentroid_x', 'actualCentroid_y']\n",
    "    G_new = from_networkx(G, group_node_attrs=features, group_edge_attrs=['distance'])\n",
    "    return G_new\n",
    "\n",
    "Graphs_pyTorch = list(map(convert_networkx_Graphs_to_pyTorchGraphs, Graphs))\n",
    "\n",
    "Graphs_pyTorch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 18], x=[9, 3], edge_attr=[18, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_networkx_Boundaries_to_pyTorchGraphs(b):\n",
    "    \"\"\"Converting networkx boundary graphs to PyTorchGeo graphs\n",
    "    \"\"\"\n",
    "    b_new = from_networkx(b, group_node_attrs=['type', 'centroid'], group_edge_attrs=['distance'])\n",
    "    return b_new\n",
    "\n",
    "Boundaries_pyTorch = list(map(convert_networkx_Boundaries_to_pyTorchGraphs, boundaries))\n",
    "\n",
    "Boundaries_pyTorch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "getting all Xs, Ys: 100%|██████████| 80787/80787 [00:05<00:00, 14664.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(247.42583732057415, 247.84313725490196, 10.666666666666666, 8.577319587628866)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_x, G_y = get_all_x_y(Graphs_pyTorch)\n",
    "G_x.max(), G_y.max(), G_x.min(), G_y.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And we saw the box plots so there is no outliers, and the distribution is normal\n",
      "We will use z-score normalization\n"
     ]
    }
   ],
   "source": [
    "# print(f\"Maximun x: {max_x}, Maximum y: {max_y}, Minimum x: {min_x}, Minimum y: {min_y}\")\n",
    "print(\"And we saw the box plots so there is no outliers, and the distribution is normal\")\n",
    "G_x_mean = G_x.mean()\n",
    "G_y_mean = G_y.mean()\n",
    "G_x_std  = G_x.std()\n",
    "G_y_std  = G_y.std()\n",
    "print(\"We will use z-score normalization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Befor: G_1 embedings are: tensor([[  0.0000, 114.4449, 153.2065],\n",
      "        [  1.0000, 207.2296, 196.9931],\n",
      "        [  2.0000,  26.6358,  34.7746],\n",
      "        [  3.0000, 222.7052, 140.5780],\n",
      "        [  3.0000, 117.2607, 101.8013],\n",
      "        [  7.0000, 163.5824, 101.4260],\n",
      "        [  7.0000, 134.9086, 201.0376]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80787/80787 [00:02<00:00, 32322.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After: G_1 embedings are: tensor([[  0.0000, 114.4449, 153.2065],\n",
      "        [  1.0000, 207.2296, 196.9931],\n",
      "        [  2.0000,  26.6358,  34.7746],\n",
      "        [  3.0000, 222.7052, 140.5780],\n",
      "        [  3.0000, 117.2607, 101.8013],\n",
      "        [  1.0000, 163.5824, 101.4260],\n",
      "        [  1.0000, 134.9086, 201.0376]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Befor: G_1 embedings are: {Graphs_pyTorch[1].x}')\n",
    "for G in tqdm(Graphs_pyTorch, total=len(Graphs_pyTorch)):\n",
    "    for j ,value in enumerate(G.x):\n",
    "        type_ = int(value[0].item())\n",
    "        \n",
    "        if type_ in [1, 4, 5, 6, 7, 8]:\n",
    "            G.x[j][0] = 1\n",
    "        \n",
    "        # making all labels from 0 to 6 only to help one_hotting\n",
    "        elif type_ == 9:\n",
    "            G.x[j][0] = 4\n",
    "        elif type_ == 10:\n",
    "            G.x[j][0] = 5\n",
    "        elif type_ == 11:\n",
    "            G.x[j][0] = 6\n",
    "\n",
    "\n",
    "print(f'After: G_1 embedings are: {Graphs_pyTorch[1].x}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80787/80787 [00:05<00:00, 14023.12it/s]\n"
     ]
    }
   ],
   "source": [
    "for G in tqdm(Graphs_pyTorch, total=len(Graphs_pyTorch)):\n",
    "    \n",
    "    # Making tensor of means = [x_mean, y_mean] & tensor of stds = [x_std, y_std].\n",
    "    # We could make a tensor of ones = [rows, 2] then multiply it by the means, But we directly \n",
    "    # multiply the means using the idea of \"Broadcasting\".\n",
    "    G.x[:, 1:] = (G.x[:, 1:] - torch.tensor([G_x_mean, G_y_mean])) / torch.tensor([G_x_std, G_y_std])\n",
    "    \n",
    "    # One hot encoding for the first column [type of rooms]\n",
    "    first_column_encodings = F.one_hot(G.x[:, 0].long(), 7)\n",
    "    \n",
    "    G.x = torch.cat([first_column_encodings, G.x[:, 1:]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now, we could return back to real values: \n",
      "tensor([[114.4449, 153.2065],\n",
      "        [207.2296, 196.9931],\n",
      "        [ 26.6358,  34.7746],\n",
      "        [222.7052, 140.5780],\n",
      "        [117.2607, 101.8013],\n",
      "        [163.5824, 101.4260],\n",
      "        [134.9086, 201.0376]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "return_to_real = Graphs_pyTorch[1].x[:, [-2, -1]] * torch.tensor([G_x_std, G_y_std]) + torch.Tensor([G_x_mean, G_y_mean])\n",
    "print(f\"Now, we could return back to real values: \\n{return_to_real}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "getting all Xs, Ys: 100%|██████████| 80787/80787 [00:07<00:00, 11105.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(340.0875912408759, 306.0, -57.6, -86.6771653543307)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_x, B_y = get_all_x_y(Boundaries_pyTorch)\n",
    "B_x.max(), B_y.max(), B_x.min(), B_y.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And we saw the box plots so there is no outliers, and the distribution is normal\n",
      "We will use z-score normalization\n"
     ]
    }
   ],
   "source": [
    "# print(f\"Maximun x: {max_x}, Maximum y: {max_y}, Minimum x: {min_x}, Minimum y: {min_y}\")\n",
    "print(\"And we saw the box plots so there is no outliers, and the distribution is normal\")\n",
    "B_x_mean = B_x.mean()\n",
    "B_y_mean = B_y.mean()\n",
    "B_x_std  = B_x.std()\n",
    "B_y_std  = B_y.std()\n",
    "print(\"We will use z-score normalization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80787/80787 [00:02<00:00, 31392.07it/s]\n"
     ]
    }
   ],
   "source": [
    "for b in tqdm(Boundaries_pyTorch, total=len(Boundaries_pyTorch)):\n",
    "    \n",
    "    # Making tensor of means = [x_mean, y_mean] & tensor of stds = [x_std, y_std].\n",
    "    # We could make a tensor of ones = [rows, 2] then multiply it by the means, But we directly \n",
    "    # multiply the means using the idea of \"Broadcasting\".\n",
    "    b.x[:, 1:] = (b.x[:, 1:] - torch.tensor([B_x_mean, B_y_mean])) / torch.tensor([B_x_std, B_y_std])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now, we could return back to real values: \n",
      "tensor([[ 3.6994e+00,  2.5008e+02],\n",
      "        [ 1.0136e+02,  2.5008e+02],\n",
      "        [ 2.5230e+02,  2.4712e+02],\n",
      "        [ 2.5230e+02,  1.1986e+02],\n",
      "        [ 1.9755e+02,  1.1986e+02],\n",
      "        [ 1.9755e+02,  6.6590e+01],\n",
      "        [ 4.9572e+01,  6.6590e+01],\n",
      "        [ 4.9572e+01, -1.0978e-06],\n",
      "        [ 3.6994e+00, -1.0978e-06],\n",
      "        [ 8.6566e+01,  6.8069e+01]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "return_to_real = Boundaries_pyTorch[1].x[:, [-2, -1]] * torch.tensor([B_x_std, B_y_std]) + torch.Tensor([B_x_mean, B_y_mean])\n",
    "print(f\"Now, we could return back to real values: \\n{return_to_real}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 64629, Val dataset: 16148, Test dataset: 10\n"
     ]
    }
   ],
   "source": [
    "class Planify_Dataset(Dataset):\n",
    "    def __init__(self, Graphs, Boundaries):\n",
    "        self.Graphs = Graphs\n",
    "        self.Boundaries = Boundaries\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.Graphs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        G = self.Graphs[index].clone().to(self.device)\n",
    "        B = self.Boundaries[index].clone().to(self.device)\n",
    "        B.x = B.x.to(G.x.dtype)\n",
    "        B.edge_index = B.edge_index.to(G.edge_index.dtype)\n",
    "        B.edge_attr = B.edge_attr.to(G.edge_attr.dtype)\n",
    "        \n",
    "        # shuffling nodes inside the same graph\n",
    "        # permutation = torch.randperm(G.num_nodes).to(self.device)\n",
    "        \n",
    "        # G.x = G.x[permutation]\n",
    "        # G.edge_index = permutation[G.edge_index]\n",
    "        # G.rec_w = G.rec_w[permutation]\n",
    "        # G.rec_h = G.rec_h[permutation]\n",
    "        # G.edge_attr = G.edge_attr[permutation]\n",
    "        \n",
    "        # padded_x = torch.nn.functional.pad(x, pad=(0, 0, 0, 8 - nu_nodes), mode='constant', value=0)\n",
    "        # padded_y = torch.nn.functional.pad(y, pad=(0, 8 - nu_nodes), mode='constant', value=0)\n",
    "        graphs = {\n",
    "            'G': G,\n",
    "            'B': B\n",
    "        }\n",
    "        \n",
    "        return graphs\n",
    "edge = int(len(Graphs_pyTorch) * 0.8)\n",
    "batch_size = 32\n",
    "train_dataset = Planify_Dataset(Graphs_pyTorch[:edge], Boundaries_pyTorch[:edge])\n",
    "train_loader  = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = Planify_Dataset(Graphs_pyTorch[edge:-10], Boundaries_pyTorch[edge:-10])\n",
    "val_loader  = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = Planify_Dataset(Graphs_pyTorch[-10:], Boundaries_pyTorch[-10:])\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(f\"Train dataset: {len(train_dataset)}, Val dataset: {len(val_dataset)}, Test dataset: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model function\n",
    "import os\n",
    "\n",
    "checkpoint_dir = \"./checkpoints\"\n",
    "\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "    \n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch):\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f'Best_model_V3.pt')\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'epoch': epoch\n",
    "    }, checkpoint_path)\n",
    "    \n",
    "    print('Model saved :)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GATNet(\n",
       "  (graph_conv1): GATConv(9, 32, heads=4)\n",
       "  (graph_conv2): GATConv(137, 32, heads=8)\n",
       "  (graph_conv3): GATConv(265, 64, heads=8)\n",
       "  (graph_conv4): GATConv(521, 128, heads=8)\n",
       "  (boundary_conv1): GATConv(3, 32, heads=4)\n",
       "  (boundary_conv2): GATConv(131, 32, heads=8)\n",
       "  (Concatination1): GATConv(1292, 128, heads=8)\n",
       "  (width_layer1): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (height_layer1): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (width_output): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (height_output): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class GATNet(torch.nn.Module):\n",
    "    def __init__(self, num_graph_node_features, num_boundary_node_features):\n",
    "        super(GATNet, self).__init__()\n",
    "        \n",
    "        self.graph_conv1 = GATConv(num_graph_node_features, 32, heads=4)\n",
    "        \n",
    "        input_of_conv2   = num_graph_node_features + 32*4\n",
    "        self.graph_conv2 = GATConv(input_of_conv2, 32, heads=8)\n",
    "        \n",
    "        input_of_conv3   = num_graph_node_features + 32*8\n",
    "        self.graph_conv3 = GATConv(input_of_conv3, 64, heads=8)\n",
    "        \n",
    "        input_of_conv4   = num_graph_node_features + 64*8\n",
    "        self.graph_conv4 = GATConv(input_of_conv4, 128, heads=8)\n",
    "        # self.graph_conv5 = GATConv(128*8, 128, heads=8)\n",
    "        # self.graph_conv6 = GATConv(128*8, 128, heads=16)\n",
    "        # self.graph_conv7 = GATConv(128*16, 256, heads=16)\n",
    "        # self.graph_conv8 = GATConv(256*16, 256, heads=16)\n",
    "        shape_of_graphs_befor_concatination = num_graph_node_features + 128*8\n",
    "        \n",
    "        self.boundary_conv1 = GATConv(num_boundary_node_features, 32, heads=4)\n",
    "        input_of_boundary_conv2 = 32*4 + num_boundary_node_features\n",
    "        self.boundary_conv2 = GATConv(input_of_boundary_conv2, 32, heads=8)\n",
    "        # self.boundary_conv3 = GATConv(32*8, 64, heads=8)\n",
    "        # self.boundary_conv4 = GATConv(64*8, 128, heads=8)\n",
    "        # self.boundary_conv5 = GATConv(128*8, 128, heads=8)\n",
    "        shape_of_boundary_befor_concatination = num_boundary_node_features + 32 * 8\n",
    "        \n",
    "        # Output of graph_conv8 + output of boundary_conv5 + 2 step connection from real nodes and boundary nodes\n",
    "        inputs_concatination = shape_of_graphs_befor_concatination + shape_of_boundary_befor_concatination\n",
    "        self.Concatination1  = GATConv(inputs_concatination, 128, heads=8)\n",
    "        # self.Concatination2  = GATConv(128*8, 64, heads=8)\n",
    "        # self.Concatination3  = GATConv(64*8, 64, heads=8)\n",
    "        # self.Concatination4  = GATConv(64*8, 32, heads=8)\n",
    "        # self.Concatination5  = GATConv(32*8, 32*4)\n",
    "        \n",
    "        # self.lin1 = nn.Linear(inputs_concatination, 256)\n",
    "        # self.lin2 = nn.Linear(256, 32)\n",
    "\n",
    "        self.width_layer1  = nn.Linear(128*8, 128)\n",
    "        self.height_layer1 = nn.Linear(128*8, 128)\n",
    "        \n",
    "        # self.width_layer2  = nn.Linear(256, 128)\n",
    "        # self.height_layer2 = nn.Linear(256, 128)\n",
    "        \n",
    "        # self.width_layer3  = nn.Linear(128, 32)\n",
    "        # self.height_layer3 = nn.Linear(128, 32)\n",
    "        \n",
    "        # self.width_layer4  = nn.Linear(32, 8)\n",
    "        # self.height_layer4 = nn.Linear(32, 8)\n",
    "        \n",
    "        self.width_output  = nn.Linear(128, 1)\n",
    "        self.height_output = nn.Linear(128, 1)\n",
    "        \n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, graph, boundary):\n",
    "        x_graph, g_edge_index, g_edge_attr, g_batch = graph.x, graph.edge_index, graph.edge_attr, graph.batch\n",
    "        x_boundary, b_edge_indexy, b_edge_attr, b_batch = boundary.x, boundary.edge_index, boundary.edge_attr, boundary.batch\n",
    "        \n",
    "        NUM_OF_NODES = x_graph.shape[0]\n",
    "        # During testing, as we input only one graph.\n",
    "        if g_batch == None:\n",
    "            g_batch = torch.zeros(x_graph.shape[0], dtype=torch.long)\n",
    "        if b_batch == None:\n",
    "            b_batch = torch.zeros(x_boundary.shape[0], dtype=torch.long)\n",
    "        \n",
    "        \n",
    "        x_graph_res = x_graph\n",
    "        x_boundary_res = x_boundary\n",
    "        \n",
    "        # Passing the graph throught a message passing to embed its features\n",
    "        x_graph = F.leaky_relu(self.graph_conv1(x_graph, g_edge_index, g_edge_attr))\n",
    "        x_graph = self.dropout(x_graph) # Concatinate with step connection from real values.\n",
    "        x_graph = torch.cat([x_graph, x_graph_res], dim=1)\n",
    "        \n",
    "        \n",
    "        x_graph = F.leaky_relu(self.graph_conv2(x_graph, g_edge_index, g_edge_attr))\n",
    "        x_graph = self.dropout(x_graph)\n",
    "        x_graph = torch.cat([x_graph, x_graph_res], dim=1)\n",
    "        \n",
    "        x_graph = F.leaky_relu(self.graph_conv3(x_graph, g_edge_index))\n",
    "        x_graph = self.dropout(x_graph) \n",
    "        x_graph = torch.cat([x_graph, x_graph_res], dim=1)\n",
    "        \n",
    "        x_graph = F.leaky_relu(self.graph_conv4(x_graph, g_edge_index))\n",
    "        x_graph = self.dropout(x_graph) \n",
    "        x_graph = torch.cat([x_graph, x_graph_res], dim=1)\n",
    "        \n",
    "        # x_graph = F.leaky_relu(self.graph_conv5(x_graph, g_edge_index))\n",
    "        # x_graph = F.leaky_relu(self.graph_conv6(x_graph, g_edge_index))\n",
    "        # x_graph = self.dropout(x_graph)\n",
    "        # x_graph = F.leaky_relu(self.graph_conv7(x_graph, g_edge_index))\n",
    "        # x_graph = F.leaky_relu(self.graph_conv8(x_graph, g_edge_index))\n",
    "        # x_graph = self.dropout(x_graph)\n",
    "        \n",
    "        \n",
    "        # Passing the boundary throught a message passing to embed its features\n",
    "        x_boundary = F.leaky_relu(self.boundary_conv1(x_boundary, b_edge_indexy, b_edge_attr))\n",
    "        x_boundary = self.dropout(x_boundary)\n",
    "        x_boundary = torch.cat([x_boundary, x_boundary_res], dim=1)\n",
    "        \n",
    "        x_boundary = F.leaky_relu(self.boundary_conv2(x_boundary, b_edge_indexy, b_edge_attr))\n",
    "        x_boundary = self.dropout(x_boundary)\n",
    "        x_boundary = torch.cat([x_boundary, x_boundary_res], dim=1)\n",
    "        \n",
    "        # x_boundary = F.leaky_relu(self.boundary_conv3(x_boundary, b_edge_indexy))\n",
    "        # x_boundary = self.dropout(x_boundary)\n",
    "        # x_boundary = F.leaky_relu(self.boundary_conv4(x_boundary, b_edge_indexy))\n",
    "        # x_boundary = F.leaky_relu(self.boundary_conv5(x_boundary, b_edge_indexy))\n",
    "        # x_boundary = self.dropout(x_boundary)\n",
    "\n",
    "        # Pooling the bounadry to 1D vector by getting max value in each feature for all nodes.\n",
    "        x_boundary_pooled = F.max_pool1d(x_boundary.transpose(0, 1), kernel_size=x_boundary.shape[0]).view(1, -1)\n",
    "        \n",
    "        # Concatinating the graph & the boundary\n",
    "        x = torch.cat([x_graph, x_boundary_pooled.repeat(NUM_OF_NODES, 1)], dim=1)\n",
    "        x = F.leaky_relu(self.Concatination1(x, g_edge_index))\n",
    "        x = self.dropout(x)\n",
    "        # x = F.leaky_relu(self.Concatination2(x, g_edge_index))\n",
    "        # x = self.dropout(x)\n",
    "        # x = F.leaky_relu(self.Concatination3(x, g_edge_index))\n",
    "        # x = self.dropout(x)\n",
    "        # x = F.leaky_relu(self.Concatination4(x, g_edge_index))\n",
    "        # x = self.dropout(x)\n",
    "        # x = F.leaky_relu(self.Concatination5(x, g_edge_index))\n",
    "        # x = self.dropout(x)\n",
    "        \n",
    "        # x = F.leaky_relu(self.lin1(x))\n",
    "        # x = self.dropout(x)\n",
    "        # x = F.leaky_relu(self.lin2(x))\n",
    "        # x = self.dropout(x)\n",
    "        \n",
    "        \n",
    "        width = F.leaky_relu(self.width_layer1(x))\n",
    "        # width = F.leaky_relu(self.width_layer2(width))\n",
    "        # width = F.leaky_relu(self.width_layer3(width))\n",
    "        # width = F.leaky_relu(self.width_layer4(width))\n",
    "        width = self.dropout(width)\n",
    "        width = self.width_output(width)\n",
    "        \n",
    "        height = F.leaky_relu(self.height_layer1(x))\n",
    "        # height = F.leaky_relu(self.height_layer2(height))\n",
    "        # height = F.leaky_relu(self.height_layer3(height))\n",
    "        # height = F.leaky_relu(self.height_layer4(height))\n",
    "        height = self.dropout(height)\n",
    "        height = self.height_output(height)\n",
    "        \n",
    "        return width.squeeze(), height.squeeze()\n",
    "\n",
    "num_graph_node_features = Graphs_pyTorch[0].x.shape[1]\n",
    "num_boundary_node_features = Boundaries_pyTorch[0].x.shape[1]\n",
    "\n",
    "model = GATNet(num_graph_node_features, num_boundary_node_features)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# to monitor the loss & accuracy.\n",
    "errors = []\n",
    "acc = []\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, train_loader):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        graph, boundary = data['G'], data['B']\n",
    "        \n",
    "        width, height    = model(graph, boundary)\n",
    "        \n",
    "        width_loss = criterion(width, graph.rec_w)\n",
    "        height_loss = criterion(height, graph.rec_h)\n",
    "\n",
    "        loss = width_loss + height_loss\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Monitoring\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    return running_loss / len(train_loader)\n",
    "\n",
    "\n",
    "def evaluate(model, criterion, val_loader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            graph, boundary = data['G'], data['B']\n",
    "            width, height    = model(graph, boundary)\n",
    "            width_loss = criterion(width, graph.rec_w)\n",
    "            height_loss = criterion(height, graph.rec_h)\n",
    "\n",
    "            loss = width_loss + height_loss\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "    return running_loss / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.001\n",
    "num_epochs = 250\n",
    "patience = 10 # Number of epochs to wait if validation loss doesn't improve\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "counter = 0\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=3e-5)\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.950)\n",
    "# Notice\n",
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Training loop with dtype conversion\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;66;03m# Convert input data to float32\u001b[39;00m\n\u001b[0;32m      8\u001b[0m         graph, boundary \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mG\u001b[39m\u001b[38;5;124m'\u001b[39m], data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      9\u001b[0m         graph\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[1;32mc:\\Users\\K.Sriram\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\K.Sriram\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\K.Sriram\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\K.Sriram\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[46], line 12\u001b[0m, in \u001b[0;36mPlanify_Dataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m     11\u001b[0m     G \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mGraphs[index]\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m---> 12\u001b[0m     B \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBoundaries\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     B\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m B\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mto(G\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m     14\u001b[0m     B\u001b[38;5;241m.\u001b[39medge_index \u001b[38;5;241m=\u001b[39m B\u001b[38;5;241m.\u001b[39medge_index\u001b[38;5;241m.\u001b[39mto(G\u001b[38;5;241m.\u001b[39medge_index\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\K.Sriram\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch_geometric\\data\\data.py:362\u001b[0m, in \u001b[0;36mBaseData.to\u001b[1;34m(self, device, non_blocking, *args)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    358\u001b[0m        non_blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;124;03m    only the ones given in :obj:`*args`.\u001b[39;00m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    363\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\K.Sriram\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch_geometric\\data\\data.py:342\u001b[0m, in \u001b[0;36mBaseData.apply\u001b[1;34m(self, func, *args)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;124;03mthe ones given in :obj:`*args`.\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m store \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstores:\n\u001b[1;32m--> 342\u001b[0m     \u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\K.Sriram\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch_geometric\\data\\storage.py:201\u001b[0m, in \u001b[0;36mBaseStorage.apply\u001b[1;34m(self, func, *args)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;124;03mthe ones given in :obj:`*args`.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems(\u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m--> 201\u001b[0m     \u001b[38;5;28mself\u001b[39m[key] \u001b[38;5;241m=\u001b[39m \u001b[43mrecursive_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\K.Sriram\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch_geometric\\data\\storage.py:897\u001b[0m, in \u001b[0;36mrecursive_apply\u001b[1;34m(data, func)\u001b[0m\n\u001b[0;32m    895\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecursive_apply\u001b[39m(data: Any, func: Callable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Tensor):\n\u001b[1;32m--> 897\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39mPackedSequence):\n\u001b[0;32m    899\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(data)\n",
      "File \u001b[1;32mc:\\Users\\K.Sriram\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch_geometric\\data\\data.py:363\u001b[0m, in \u001b[0;36mBaseData.to.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    358\u001b[0m        non_blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;124;03m    only the ones given in :obj:`*args`.\u001b[39;00m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m--> 363\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39margs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Ensure the model is in float32\n",
    "model = model.float()\n",
    "\n",
    "# Training loop with dtype conversion\n",
    "for epoch in range(num_epochs):\n",
    "    for data in train_loader:\n",
    "        # Convert input data to float32\n",
    "        graph, boundary = data['G'], data['B']\n",
    "        graph.x = graph.x.float()\n",
    "        boundary.x = boundary.x.float()\n",
    "        \n",
    "        # Perform forward pass\n",
    "        width, height = model(graph, boundary)\n",
    "\n",
    "        # Compute losses\n",
    "        width_loss = criterion(width, graph.rec_w.float())\n",
    "        height_loss = criterion(height, graph.rec_h.float())\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss = width_loss + height_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating ...\n",
      "Epoch [1/250], Train Loss: 515.0430, Validation Loss: 507.8643\n",
      "Validating ...\n",
      "Epoch [1/250], Train Loss: 498.7299, Validation Loss: 639.2898\n",
      "Validating ...\n",
      "Epoch [2/250], Train Loss: 483.8221, Validation Loss: 586.4366\n",
      "Validating ...\n",
      "Epoch [2/250], Train Loss: 474.8743, Validation Loss: 568.6414\n",
      "Learning rate decreased!, now is 0.00095\n",
      "Validating ...\n",
      "Epoch [3/250], Train Loss: 462.4626, Validation Loss: 559.8230\n",
      "Validating ...\n",
      "Epoch [3/250], Train Loss: 454.4844, Validation Loss: 551.7100\n",
      "Validating ...\n",
      "Epoch [4/250], Train Loss: 446.9422, Validation Loss: 539.6363\n",
      "Validating ...\n",
      "Epoch [4/250], Train Loss: 441.4487, Validation Loss: 443.5761\n",
      "Model saved :)\n",
      "Validating ...\n",
      "Epoch [5/250], Train Loss: 435.2534, Validation Loss: 461.0971\n",
      "Validating ...\n",
      "Epoch [5/250], Train Loss: 429.5580, Validation Loss: 456.4961\n",
      "Validating ...\n",
      "Epoch [6/250], Train Loss: 424.8016, Validation Loss: 483.6802\n",
      "Validating ...\n",
      "Epoch [6/250], Train Loss: 422.2364, Validation Loss: 447.0342\n",
      "Learning rate decreased!, now is 0.0009025\n",
      "Validating ...\n",
      "Epoch [7/250], Train Loss: 413.9221, Validation Loss: 394.9006\n",
      "Validating ...\n",
      "Epoch [7/250], Train Loss: 410.7536, Validation Loss: 414.1945\n",
      "Validating ...\n",
      "Epoch [8/250], Train Loss: 406.1769, Validation Loss: 475.8337\n",
      "Validating ...\n",
      "Epoch [8/250], Train Loss: 401.3581, Validation Loss: 400.4661\n",
      "Learning rate decreased!, now is 0.000857375\n",
      "Validating ...\n",
      "Epoch [9/250], Train Loss: 397.3702, Validation Loss: 427.2976\n",
      "Validating ...\n",
      "Epoch [9/250], Train Loss: 394.4493, Validation Loss: 477.7257\n",
      "Validating ...\n",
      "Epoch [10/250], Train Loss: 389.2306, Validation Loss: 430.7338\n",
      "Validating ...\n",
      "Epoch [10/250], Train Loss: 387.0627, Validation Loss: 387.4412\n",
      "Model saved :)\n",
      "Validating ...\n",
      "Epoch [11/250], Train Loss: 384.1735, Validation Loss: 363.8053\n",
      "Validating ...\n",
      "Epoch [11/250], Train Loss: 381.5839, Validation Loss: 423.3089\n",
      "Validating ...\n",
      "Epoch [12/250], Train Loss: 380.2104, Validation Loss: 406.3460\n",
      "Validating ...\n",
      "Epoch [12/250], Train Loss: 376.9860, Validation Loss: 369.8641\n",
      "Learning rate decreased!, now is 0.0008145062499999999\n",
      "Validating ...\n",
      "Epoch [13/250], Train Loss: 374.0029, Validation Loss: 371.7453\n",
      "Validating ...\n",
      "Epoch [13/250], Train Loss: 370.5993, Validation Loss: 413.0995\n",
      "Validating ...\n",
      "Epoch [14/250], Train Loss: 367.5766, Validation Loss: 388.5245\n",
      "Validating ...\n",
      "Epoch [14/250], Train Loss: 365.5143, Validation Loss: 384.1746\n",
      "Learning rate decreased!, now is 0.0007737809374999998\n",
      "Validating ...\n",
      "Epoch [15/250], Train Loss: 361.9036, Validation Loss: 354.5078\n",
      "Validating ...\n",
      "Epoch [15/250], Train Loss: 359.9534, Validation Loss: 362.3300\n",
      "Validating ...\n",
      "Epoch [16/250], Train Loss: 357.8828, Validation Loss: 349.3178\n",
      "Validating ...\n",
      "Epoch [16/250], Train Loss: 355.1359, Validation Loss: 391.8976\n",
      "Learning rate decreased!, now is 0.0007350918906249997\n",
      "Validating ...\n",
      "Epoch [17/250], Train Loss: 353.0378, Validation Loss: 377.9945\n",
      "Validating ...\n",
      "Epoch [17/250], Train Loss: 350.3760, Validation Loss: 354.4848\n",
      "Validating ...\n",
      "Epoch [18/250], Train Loss: 351.8036, Validation Loss: 382.8204\n",
      "Validating ...\n",
      "Epoch [18/250], Train Loss: 347.2190, Validation Loss: 349.3630\n",
      "Learning rate decreased!, now is 0.0006983372960937497\n",
      "Validating ...\n",
      "Epoch [19/250], Train Loss: 343.1279, Validation Loss: 353.2036\n",
      "Validating ...\n",
      "Epoch [19/250], Train Loss: 342.5071, Validation Loss: 379.5050\n",
      "Validating ...\n",
      "Epoch [20/250], Train Loss: 340.9954, Validation Loss: 352.6127\n",
      "Validating ...\n",
      "Epoch [20/250], Train Loss: 339.0291, Validation Loss: 362.8321\n",
      "Validation loss did not improve for 10 epochs. Stopping early.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt # Make sure to import matplotlib\n",
    "\n",
    "def train(model, optimizer, criterion, train_loader):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        graph, boundary = data['G'], data['B']\n",
    "        \n",
    "        # Ensure graph and boundary features are float32\n",
    "        if graph.x.dtype != torch.float32:\n",
    "            graph.x = graph.x.type(torch.float32)\n",
    "        if boundary.x.dtype != torch.float32:\n",
    "            boundary.x = boundary.x.type(torch.float32)\n",
    "            \n",
    "        width, height = model(graph, boundary)\n",
    "\n",
    "        width_loss = criterion(width, graph.rec_w)\n",
    "        height_loss = criterion(height, graph.rec_h)\n",
    "\n",
    "        loss = width_loss + height_loss\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Monitoring\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    return running_loss / len(train_loader)\n",
    "\n",
    "def evaluate(model, criterion, val_loader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            graph, boundary = data['G'], data['B']\n",
    "            \n",
    "            # Ensure graph and boundary features are float32\n",
    "            if graph.x.dtype != torch.float32:\n",
    "                graph.x = graph.x.type(torch.float32)\n",
    "            if boundary.x.dtype != torch.float32:\n",
    "                boundary.x = boundary.x.type(torch.float32)\n",
    "                \n",
    "            width, height = model(graph, boundary)\n",
    "            width_loss = criterion(width, graph.rec_w)\n",
    "            height_loss = criterion(height, graph.rec_h)\n",
    "\n",
    "            loss = width_loss + height_loss\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    return running_loss / len(val_loader)\n",
    "\n",
    "# Assuming the following imports are in place:\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from copy import deepcopy\n",
    "# Assuming train_loader, val_loader, model, num_epochs, patience are defined\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.001\n",
    "num_epochs = 250\n",
    "patience = 10  # Number of epochs to wait if validation loss doesn't improve\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "counter = 0\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=3e-5)\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.950)\n",
    "\n",
    "# Lists to store losses\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training loop\n",
    "    train_loss = train(model, optimizer, criterion, train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Evaluation loop\n",
    "    print('Validating ...')\n",
    "    val_loss = evaluate(model, criterion, val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    # Printing and monitoring\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = deepcopy\n",
    "    # Training loop\n",
    "    train_loss = train(model, optimizer, criterion, train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Evaluation loop\n",
    "    print('Validating ...')\n",
    "    val_loss = evaluate(model, criterion, val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # Printing and monitoring\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "    \n",
    "    \n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = deepcopy(model)\n",
    "        save_checkpoint(best_model, optimizer, epoch)\n",
    "        counter = 0\n",
    "        \n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(f'Validation loss did not improve for {patience} epochs. Stopping early.')\n",
    "            break\n",
    "        if counter in range(2, 20, 2):\n",
    "            scheduler.step()\n",
    "            print(f\"Learning rate decreased!, now is {optimizer.state_dict()['param_groups'][0]['lr']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating ...\n",
      "Epoch [1/250], Train Loss: 339.0013, Validation Loss: 340.0669\n",
      "Model saved :)\n",
      "Validating ...\n",
      "Epoch [2/250], Train Loss: 337.5331, Validation Loss: 347.1623\n",
      "Validating ...\n",
      "Epoch [3/250], Train Loss: 336.1604, Validation Loss: 329.9957\n",
      "Model saved :)\n",
      "Validating ...\n",
      "Epoch [4/250], Train Loss: 333.9638, Validation Loss: 358.3170\n",
      "Validating ...\n",
      "Epoch [5/250], Train Loss: 332.9727, Validation Loss: 343.6228\n",
      "Learning rate decreased!, now is 0.0006634204312890621\n",
      "Validating ...\n",
      "Epoch [6/250], Train Loss: 330.5574, Validation Loss: 340.2958\n",
      "Validating ...\n",
      "Epoch [7/250], Train Loss: 330.6187, Validation Loss: 339.2308\n",
      "Learning rate decreased!, now is 0.000630249409724609\n",
      "Validating ...\n",
      "Epoch [8/250], Train Loss: 326.8645, Validation Loss: 352.0944\n",
      "Validating ...\n",
      "Epoch [9/250], Train Loss: 326.1803, Validation Loss: 350.3014\n",
      "Learning rate decreased!, now is 0.0005987369392383785\n",
      "Validating ...\n",
      "Epoch [10/250], Train Loss: 323.4692, Validation Loss: 333.4808\n",
      "Validating ...\n",
      "Epoch [11/250], Train Loss: 321.6705, Validation Loss: 351.9717\n",
      "Learning rate decreased!, now is 0.0005688000922764595\n",
      "Validating ...\n",
      "Epoch [12/250], Train Loss: 319.5826, Validation Loss: 358.3516\n",
      "Validating ...\n",
      "Epoch [13/250], Train Loss: 318.2381, Validation Loss: 334.2082\n",
      "Validation loss did not improve for 10 epochs. Stopping early.\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    # Training loop\n",
    "    train_loss = train(model, optimizer, criterion, train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Evaluation loop\n",
    "    print('Validating ...')\n",
    "    val_loss = evaluate(model, criterion, val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # Printing and monitoring\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "    \n",
    "    \n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = deepcopy(model)\n",
    "        save_checkpoint(best_model, optimizer, epoch)\n",
    "        counter = 0\n",
    "        \n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(f'Validation loss did not improve for {patience} epochs. Stopping early.')\n",
    "            break\n",
    "        if counter in range(2, 20, 2):\n",
    "            scheduler.step()\n",
    "            print(f\"Learning rate decreased!, now is {optimizer.state_dict()['param_groups'][0]['lr']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating ...\n",
      "Epoch [1/250], Train Loss: 317.5596, Validation Loss: 322.9034\n",
      "Model saved :)\n",
      "Validating ...\n",
      "Epoch [2/250], Train Loss: 316.2137, Validation Loss: 333.0959\n",
      "Validating ...\n",
      "Epoch [3/250], Train Loss: 314.9534, Validation Loss: 345.0229\n",
      "Learning rate decreased!, now is 0.0005403600876626365\n",
      "Validating ...\n",
      "Epoch [4/250], Train Loss: 312.5060, Validation Loss: 357.8416\n",
      "Validating ...\n",
      "Epoch [5/250], Train Loss: 311.7561, Validation Loss: 333.6687\n",
      "Learning rate decreased!, now is 0.0005133420832795047\n",
      "Validating ...\n",
      "Epoch [6/250], Train Loss: 309.0945, Validation Loss: 315.8982\n",
      "Model saved :)\n",
      "Validating ...\n",
      "Epoch [7/250], Train Loss: 313.7688, Validation Loss: 332.4559\n",
      "Validating ...\n",
      "Epoch [8/250], Train Loss: 310.4241, Validation Loss: 330.3779\n",
      "Learning rate decreased!, now is 0.00048767497911552944\n",
      "Validating ...\n",
      "Epoch [9/250], Train Loss: 305.7590, Validation Loss: 344.0363\n",
      "Validating ...\n",
      "Epoch [10/250], Train Loss: 304.5286, Validation Loss: 331.9116\n",
      "Learning rate decreased!, now is 0.00046329123015975297\n",
      "Validating ...\n",
      "Epoch [11/250], Train Loss: 303.0737, Validation Loss: 326.2482\n",
      "Validating ...\n",
      "Epoch [12/250], Train Loss: 301.9479, Validation Loss: 318.9017\n",
      "Learning rate decreased!, now is 0.0004401266686517653\n",
      "Validating ...\n",
      "Epoch [13/250], Train Loss: 300.6574, Validation Loss: 323.0879\n",
      "Validating ...\n",
      "Epoch [14/250], Train Loss: 299.2047, Validation Loss: 324.3292\n",
      "Learning rate decreased!, now is 0.00041812033521917703\n",
      "Validating ...\n",
      "Epoch [15/250], Train Loss: 297.5555, Validation Loss: 320.9623\n",
      "Validating ...\n",
      "Epoch [16/250], Train Loss: 296.7414, Validation Loss: 330.8928\n",
      "Validation loss did not improve for 10 epochs. Stopping early.\n"
     ]
    }
   ],
   "source": [
    "ounter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    # Training loop\n",
    "    train_loss = train(model, optimizer, criterion, train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Evaluation loop\n",
    "    print('Validating ...')\n",
    "    val_loss = evaluate(model, criterion, val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # Printing and monitoring\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "    \n",
    "    \n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = deepcopy(model)\n",
    "        save_checkpoint(best_model, optimizer, epoch)\n",
    "        counter = 0\n",
    "        \n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(f'Validation loss did not improve for {patience} epochs. Stopping early.')\n",
    "            break\n",
    "        if counter in range(2, 20, 2):\n",
    "            scheduler.step()\n",
    "            print(f\"Learning rate decreased!, now is {optimizer.state_dict()['param_groups'][0]['lr']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAACQE0lEQVR4nOzdd3hU1dbA4d+k94QkpEEInRB6EwIoIEhEVBSkSVWEq6Jivci9fHbFLtiwXkBpiooFpQQERLpA6IQWSIAUWnrPnO+PnZkUUmaSSV/v88wzZ+acOWfPEDIre6+9tk7TNA0hhBBCiFrEqqYbIIQQQghRnAQoQgghhKh1JEARQgghRK0jAYoQQgghah0JUIQQQghR60iAIoQQQohaRwIUIYQQQtQ6EqAIIYQQotaxqekGVIRer+fSpUu4urqi0+lqujlCCCGEMIGmaaSkpBAQEICVVdl9JHUyQLl06RKBgYE13QwhhBBCVEBMTAxNmzYt85g6GaC4uroC6g26ubnVcGuEEEIIYYrk5GQCAwON3+NlMTtAuXjxIrNnz2bt2rWkp6fTunVrFi1aRM+ePQGYOnUqS5YsKfKasLAw1q1bZ3x87do1Hn/8cX777TesrKwYNWoUCxYswMXFxaQ2GIZ13NzcJEARQggh6hhT0jPMClCuX79Ov379GDRoEGvXrqVx48acOnWKRo0aFTnu9ttvZ9GiRcbH9vb2RfZPmDCB2NhYwsPDycnJ4YEHHmDGjBksX77cnOYIIYQQop4yK0B56623CAwMLBJ8tGjR4obj7O3t8fPzK/Ecx48fZ926dezdu9fY6/LRRx9xxx138O677xIQEGBOk4QQQghRD5k1zfjXX3+lZ8+ejB49Gh8fH7p168aXX355w3FbtmzBx8eHdu3a8cgjj3D16lXjvp07d+Lh4WEMTgCGDBmClZUVu3fvLvG6WVlZJCcnF7kJIYQQov4yqwfl7NmzLFy4kKeffpr//Oc/7N27lyeeeAI7OzumTJkCqOGdkSNH0qJFC86cOcN//vMfhg0bxs6dO7G2tiYuLg4fH5+ijbCxwdPTk7i4uBKvO2/ePF5++eUKvkUhhFA0TSM3N5e8vLyabooQ9ZK1tTU2NjYWKQFiVoCi1+vp2bMnb7zxBgDdunXjyJEjfPbZZ8YAZdy4ccbjO3XqROfOnWnVqhVbtmxh8ODBFWrknDlzePrpp42PDVnAQghhquzsbGJjY0lPT6/ppghRrzk5OeHv74+dnV2lzmNWgOLv709ISEiR59q3b8+PP/5Y6mtatmyJt7c3p0+fZvDgwfj5+ZGQkFDkmNzcXK5du1Zq3oq9vf0NibZCCGEqvV5PVFQU1tbWBAQEYGdnJ0UehbAwTdPIzs7m8uXLREVF0aZNm3KLsZXFrAClX79+REZGFnnu5MmTBAUFlfqaCxcucPXqVfz9/QEIDQ0lMTGRffv20aNHDwD+/PNP9Ho9vXv3Nrf9QghRruzsbPR6PYGBgTg5OdV0c4SotxwdHbG1teX8+fNkZ2fj4OBQ4XOZFdo89dRT7Nq1izfeeIPTp0+zfPlyvvjiC2bOnAlAamoqzz33HLt27eLcuXNs2rSJESNG0Lp1a8LCwgDV43L77bczffp09uzZw/bt23nssccYN26czOARQlSpyvw1J4QwjaX+n5l1ll69erF69WpWrFhBx44defXVV5k/fz4TJkwAVHLMoUOHuPvuu2nbti3Tpk2jR48ebNu2rcgQzbJlywgODmbw4MHccccd9O/fny+++MIib0gIIYQQdZ9O0zStphthruTkZNzd3UlKSpJKskKIcmVmZhIVFUWLFi0q1eUsLGfgwIF07dqV+fPnm3T8uXPnaNGiBQcOHKBr165V2jZz1ea21YSy/r+Z8/0t/Z1CCFFLTZ06FZ1OZ7x5eXlx++23c+jQIYtd46WXXjLpS3Xq1Kncc889FrvuTz/9xKuvvmry8YGBgcTGxtKxY0eLtaG++umnn7jtttto3Lgxbm5uhIaGsn79+iLHpKSk8OSTTxIUFISjoyN9+/Zl7969RY4p/LNX+PbOO+9Uy/uQAEUIIWqx22+/ndjYWGJjY9m0aRM2NjbceeedNd2sUuXk5Jh0nKenp0kLxhlYW1vj5+eHjU2dXOO2Wv3111/cdttt/PHHH+zbt49BgwZx1113ceDAAeMxDz30EOHh4Xz77bccPnyYoUOHMmTIEC5evGg8xvBzZ7j973//Q6fTMWrUqOp5I1odlJSUpAFaUlJS9V009pCmbf9Q03Jzqu+aQgiLyMjI0I4dO6ZlZGTUdFPMMmXKFG3EiBFFntu2bZsGaAkJCcbnoqOjtdGjR2vu7u5ao0aNtLvvvluLiooy7t+8ebPWq1cvzcnJSXN3d9f69u2rnTt3Tlu0aJEGFLktWrTohna8+OKLNxy3efNmLSoqSgO0lStXarfccotmb2+vLVq0SLty5Yo2btw4LSAgQHN0dNQ6duyoLV++vMg5BwwYoM2aNcv4OCgoSHv99de1Bx54QHNxcdECAwO1zz//3LjfcK0DBw4Y3xOgbdy4UevRo4fm6OiohYaGaidOnChynVdffVVr3Lix5uLiok2bNk2bPXu21qVLF7P+HcpTvG2apmlbtmzRevXqpdnZ2Wl+fn7a7NmztZycgu+PVatWaR07dtQcHBw0T09PbfDgwVpqaqrxvZX071UZISEh2ssvv6xpmqalp6dr1tbW2po1a4oc0717d+2///1vqecYMWKEduutt5Z7rbL+v5nz/S09KKZa/x/YMBdObajplgghKknTNNKzc2vkplUi7S81NZWlS5fSunVrvLy8ANVjERYWhqurK9u2bWP79u24uLhw++23k52dTW5uLvfccw8DBgzg0KFD7Ny5kxkzZqDT6Rg7dizPPPMMHTp0MP6VPHbs2Buu++yzzzJmzJgivTl9+/Y17n/++eeZNWsWx48fJywsjMzMTHr06MHvv//OkSNHmDFjBpMmTWLPnj1lvr/33nuPnj17cuDAAR599FEeeeSRG0pbFPff//6X9957j3/++QcbGxsefPBB475ly5bx+uuv89Zbb7Fv3z6aNWvGwoULzfnIK+TixYvccccd9OrVi4MHD7Jw4UK+/vprXnvtNUD1TIwfP54HH3yQ48ePs2XLFkaOHGmsdFzavxeofBedTseWLVtMbo9eryclJQVPT08AYzXl4vkhjo6O/P333yWeIz4+nt9//51p06ZV4BOpGOkrM1XaFXV/9VTNtkMIUWkZOXmEvLC+/AOrwLFXwnCyM/1X75o1a3BxcQEgLS0Nf39/1qxZY5zK+d1336HX6/nqq6+MX2KLFi3Cw8ODLVu20LNnT5KSkrjzzjtp1aoVoMo9GLi4uGBjY1NqoUzDMY6OjmRlZZV43JNPPsnIkSOLPPfss88atx9//HHWr1/P999/z0033VTqde644w4effRRAGbPns0HH3zA5s2badeuXamvef311xkwYACgAqXhw4eTmZmJg4MDH330EdOmTeOBBx4A4IUXXmDDhg2kpqaWej5L+PTTTwkMDOTjjz9Gp9MRHBzMpUuXmD17Ni+88AKxsbHk5uYycuRIYx2xTp06AXDt2rUy/71sbW1p166dWfV83n33XVJTUxkzZgwArq6uhIaG8uqrr9K+fXt8fX1ZsWIFO3fupHXr1iWeY8mSJbi6ut7w71yVpAfFVFn5P9CJ0TXbDiFEgzJo0CAiIiKIiIhgz549hIWFMWzYMM6fPw/AwYMHOX36NK6urri4uODi4oKnpyeZmZmcOXMGT09Ppk6dSlhYGHfddRcLFiwgNjbWom0svPgrQF5eHq+++iqdOnXC09MTFxcX1q9fT3R02b8/O3fubNzW6XQlVh4v6zWGgqCG10RGRt4QEJUVIFnK8ePHCQ0NLVKtuF+/fqSmpnLhwgW6dOnC4MGD6dSpE6NHj+bLL7/k+vXrAOX+ezVp0oQTJ06Y/D6WL1/Oyy+/zPfff19kHbxvv/0WTdNo0qQJ9vb2fPjhh4wfP77UGib/+9//mDBhQrXOgpMeFFNlp6j76+drth1CiEpztLXm2CthNXZtczg7Oxf5q/arr77C3d2dL7/8ktdee43U1FR69OjBsmXLbnht48aNAdWj8sQTT7Bu3Tq+++475s6dS3h4OH369KncmynUxsLeeecdFixYwPz58+nUqRPOzs48+eSTZGdnl3keW1vbIo91Oh16vd7k1xgCgvJeU9Osra0JDw9nx44dbNiwgY8++oj//ve/7N69mxYtWljs32vlypU89NBDrFq1iiFDhhTZ16pVK7Zu3UpaWhrJycn4+/szduxYWrZsecN5tm3bRmRkJN99912l3re5pAfFFJoGWfkBSqIEKELUdTqdDic7mxq5VXYNIJ1Oh5WVFRkZGQB0796dU6dO4ePjQ+vWrYvc3N3dja/r1q0bc+bMYceOHXTs2JHly5cDYGdnZ9LqzqYeB7B9+3ZGjBjBxIkT6dKlCy1btuTkyZMVeLeV065duxumzhZ/XBXat2/Pzp07i+Qbbd++HVdXV5o2bQqof8d+/frx8ssvc+DAAezs7Fi9erXx+NL+vUy1YsUKHnjgAVasWMHw4cNLPc7Z2Rl/f3+uX7/O+vXrGTFixA3HfP311/To0YMuXbqY1YbKkgDFFLlZoM9V24nRKmARQohqkJWVRVxcHHFxcRw/fpzHH3+c1NRU7rrrLgAmTJiAt7c3I0aMYNu2bURFRbFlyxaeeOIJLly4QFRUFHPmzGHnzp2cP3+eDRs2cOrUKWNeQ/PmzYmKiiIiIoIrV66QlZVVYjuaN2/OoUOHiIyM5MqVK2VOJ27Tpo2xh+D48eP861//Ij4+3vIfTjkef/xxvv76a5YsWcKpU6d47bXXOHToUJUvFPnoo48SExPD448/zokTJ/jll1948cUXefrpp7GysmL37t288cYb/PPPP0RHR/PTTz9x+fJl2rdvX+6/18WLFwkODi4z4Xj58uVMnjyZ9957j969ext/fpKSkozHrF+/nnXr1hEVFUV4eDiDBg0iODjYmK9jkJyczKpVq3jooYeq5sMqgwzxmCK7UEJVbiakJoCrb821RwjRYKxbt86YW+Hq6kpwcDCrVq1i4MCBgFra/q+//mL27NmMHDmSlJQUmjRpwuDBg3FzcyMjI4MTJ06wZMkS48KtM2fO5F//+hcAo0aN4qeffmLQoEEkJiayaNEipk6dekM7pk+fbky6TU1NZfPmzTRv3rzENs+dO5ezZ88SFhaGk5MTM2bM4J577inyBVkdJkyYwNmzZ3n22WfJzMxkzJgxTJ06tdzZRJXVpEkT/vjjD5577jm6dOmCp6cn06ZNY+7cuQC4ubnx119/MX/+fJKTkwkKCuK9995j2LBhxMfHl/nvlZOTQ2RkJOnp6aVe/4svviA3N5eZM2ca18oDmDJlCosXLwYgKSmJOXPmcOHCBTw9PRk1ahSvv/76DcNsK1euRNM0xo8fb+FPqXxS6t4U16Lgw64Fj6eFQ2DVJ1oJISxDSt0Lg9tuuw0/Pz++/fbbmm5KvWWpUvfSg2KK7GJT0q6flwBFCCFqufT0dD777DPCwsKwtrZmxYoVbNy4kfDw8JpumjCBBCimyCoWoCSeq5FmCCGEMJ1Op+OPP/7g9ddfJzMzk3bt2vHjjz/eMKNF1E4SoJjCMIPHQGqhCCFErefo6MjGjRtruhmigmQWjymyiwUoUgtFCCGEqFISoJjCMMRjn19TQGqhCCGEEFVKAhRTGJJkfTuo+6QLoDetYJEQQgghzCcBiikMPSjercHKVhVtS75Us20SQggh6jEJUExhyEFxcAd3VaZYhnmEEEKIqiMBiikMs3jsXKGRWhpbEmWFEEKIqiMBiimMSbKu4NFMbctUYyGEMMvAgQN58sknjY+bN2/O/Pnzy3yNTqfj559/rvS1LXWesrz00kt07dq1Sq/RkEiAYgpDkqy9C3jk96DIEI8QoopNnToVnU5nvHl5eXH77bdz6NAhi12jJr9U9+7dy4wZMyx6ztLeT2xsLMOGDbPotWq7l156ieDgYJydnWnUqBFDhgxh9+7dRY55/fXX6du3L05OTnh4eJR6rsWLF9O5c2ccHBzw8fEpssZPVZEAxRSGHhQ7F2jUXG3LEI8QohrcfvvtxMbGEhsby6ZNm7CxseHOO++s6WZZROPGjXFycqqWa/n5+WFvb18t16ot2rZty8cff8zhw4f5+++/ad68OUOHDuXy5cvGY7Kzsxk9ejSPPPJIqed5//33+e9//8vzzz/P0aNH2bhxI2FhYVXefglQTGFIkrV3lR4UIUS1sre3x8/PDz8/P7p27crzzz9PTExMkS+ZmJgYxowZg4eHB56enowYMYJz584Z92/ZsoWbbroJZ2dnPDw86NevH+fPn2fx4sW8/PLLHDx40NhLY1jttrANGzbg4OBAYmJikednzZrFrbfeCsDVq1cZP348TZo0wcnJiU6dOrFixYoy31vxIZ5Tp05xyy234ODgQEhISIlr5syePZu2bdvi5OREy5Yt+b//+z9ycnIAynw/xYd4Dh8+zK233oqjoyNeXl7MmDGD1NSCZU2mTp3KPffcw7vvvou/vz9eXl7MnDnTeC1T6PV6XnnlFZo2bYq9vT1du3Zl3bp1xv3Z2dk89thj+Pv74+DgQFBQEPPmzQNA0zReeuklmjVrhr29PQEBATzxxBMmXxvg/vvvZ8iQIbRs2ZIOHTrw/vvvk5ycXKQH7uWXX+app56iU6dOJZ7j+vXrzJ07l2+++Yb777+fVq1a0blzZ+6++26z2lIRUureFIV7UAw5KMmXIDcbbOxqrl1CiIrRNMgpfbn6KmXrBDpdhV6amprK0qVLad26NV5eXgDk5OQQFhZGaGgo27Ztw8bGhtdee804FGRlZcU999zD9OnTWbFiBdnZ2ezZswedTsfYsWM5cuQI69atM5aEd3d3v+G6gwcPxsPDgx9//JFp06YBkJeXx3fffcfrr78OqBVse/TowezZs3Fzc+P3339n0qRJtGrViptuKn9xVb1ez8iRI/H19WX37t0kJSUVyVcxcHV1ZfHixQQEBHD48GGmT5+Oq6sr//73v01+P2lpacbPbO/evSQkJPDQQw/x2GOPFQnQNm/ejL+/P5s3b+b06dOMHTuWrl27Mn369HLfD8CCBQt47733+Pzzz+nWrRv/+9//uPvuuzl69Cht2rThww8/5Ndff+X777+nWbNmxMTEEBMTA8CPP/7IBx98wMqVK+nQoQNxcXEcPHjQeO6XXnqJxYsXFwlEy5Kdnc0XX3yBu7s7Xbp0Mek1AOHh4ej1ei5evEj79u1JSUmhb9++vPfeewQGBpp8noqQAMUUhlk89i7g4gM2jpCbAUkx4NWqZtsmhDBfTjq8EVAz1/7PJbBzNvnwNWvW4OLiAqgvVn9/f9asWYOVleoA/+6779Dr9Xz11Vfo8gOfRYsW4eHhwZYtW+jZsydJSUnceeedtGqlfl+1b9/eeH4XFxdsbGzw8/MrtQ3W1taMGzeO5cuXGwOUTZs2kZiYyKhRowBo0qQJzz77rPE1jz/+OOvXr+f77783KUDZuHEjJ06cYP369QQEqH+bN95444a8kblz5xq3mzdvzrPPPsvKlSv597//jaOjo0nvZ/ny5WRmZvLNN9/g7Kz+LT7++GPuuusu3nrrLXx9fQFo1KgRH3/8MdbW1gQHBzN8+HA2bdpkcoDy7rvvMnv2bMaNGwfAW2+9xebNm5k/fz6ffPIJ0dHRtGnThv79+6PT6QgKCjK+Njo6Gj8/P4YMGYKtrS3NmjUr8jl6e3sb/z3LsmbNGsaNG0d6ejr+/v6Eh4fj7e1tUvsBzp49i16v54033mDBggW4u7szd+5cbrvtNg4dOoSdXdX9kS5DPKbILjSLR6crNJNHhnmEEFVr0KBBREREEBERwZ49ewgLC2PYsGGcP69+/xw8eJDTp0/j6uqKi4sLLi4ueHp6kpmZyZkzZ/D09GTq1KmEhYVx1113sWDBAmJjY81ux4QJE9iyZQuXLqkilcuWLWP48OHGxMq8vDxeffVVOnXqhKenJy4uLqxfv57oaNNmPB4/fpzAwEBjcAIQGhp6w3Hfffcd/fr1w8/PDxcXF+bOnWvyNQpfq0uXLsbgBKBfv37o9XoiIyONz3Xo0AFra2vjY39/fxISEky6RnJyMpcuXaJfv35Fnu/Xrx/Hjx8H1DBSREQE7dq144knnmDDhg3G40aPHk1GRgYtW7Zk+vTprF69mtzcXOP+xx57jE2bNpXbDsPPz44dO7j99tsZM2aMye8BVM9WTk4OH374IWFhYfTp04cVK1Zw6tQpNm/ebPJ5KkJ6UMqjzyvoCrZzVfeNguBKpCTKClFX2TqpnoyaurYZnJ2dad26tfHxV199hbu7O19++SWvvfYaqamp9OjRg2XLlt3w2saNGwOqR+WJJ55g3bp1fPfdd8ydO5fw8HD69Oljcjt69epFq1atWLlyJY888girV68uMhzyzjvvsGDBAubPn0+nTp1wdnbmySefJDs726z3W5adO3cyYcIEXn75ZcLCwnB3d2flypW89957FrtGYba2tkUe63Q69Hq9xc7fvXt3oqKiWLt2LRs3bmTMmDEMGTKEH374gcDAQCIjI9m4cSPh4eE8+uijvPPOO2zduvWGdpXF8PPTunVr+vTpQ5s2bfj666+ZM2eOSa/39/cHICQkxPhc48aN8fb2NjswNJcEKOXJLkiawl51s0otFCHqOJ3OrGGW2kSn02FlZUVGRgagvuS+++47fHx8cHNzK/V13bp1o1u3bsyZM4fQ0FCWL19Onz59sLOzIy/PtLXFJkyYwLJly2jatClWVlYMHz7cuG/79u2MGDGCiRMnAuov75MnTxb5YitL+/btiYmJITY21viluGvXriLH7Nixg6CgIP773/8anzP0JBmY8n7at2/P4sWLSUtLM/aibN++HSsrK9q1a2dSe8vj5uZGQEAA27dvZ8CAAcbnt2/fXmSoxs3NjbFjxzJ27Fjuu+8+br/9dq5du4anpyeOjo7cdddd3HXXXcycOZPg4GAOHz5M9+7dK9wuvV5PVlaWyccbeoAiIyNp2lRVUr927RpXrlwpMiRVFWSIpzyGBFkrW7DJn6ImM3mEENUkKyuLuLg44uLiOH78OI8//jipqancddddgAoavL29GTFiBNu2bSMqKootW7bwxBNPcOHCBaKiopgzZw47d+7k/PnzbNiwgVOnThnzUJo3b05UVBQRERFcuXKlzC+vCRMmsH//fl5//XXuu+++ItN227RpQ3h4ODt27OD48eP861//Ij4+3uT3OWTIENq2bcuUKVM4ePAg27ZtKxKIGK4RHR3NypUrOXPmDB9++CGrV68ucowp72fChAk4ODgwZcoUjhw5wubNm3n88ceZNGmSMf/EEp577jneeustvvvuOyIjI3n++eeJiIhg1qxZgJq+u2LFCk6cOMHJkydZtWoVfn5+eHh4sHjxYr7++muOHDnC2bNnWbp0KY6Ojsag4OOPP2bw4MGlXjstLY3//Oc/7Nq1i/Pnz7Nv3z4efPBBLl68yOjRo43HRUdHExERQXR0NHl5ecbhRMOMprZt2zJixAhmzZrFjh07OHLkCFOmTCE4OJhBgwZZ7LMqkVYHJSUlaYCWlJRU9RdLOKFpL7pp2ptBBc8d/Vk998WtVX99IUSlZWRkaMeOHdMyMjJquilmmTJligYYb66urlqvXr20H374ochxsbGx2uTJkzVvb2/N3t5ea9mypTZ9+nQtKSlJi4uL0+655x7N399fs7Oz04KCgrQXXnhBy8vL0zRN0zIzM7VRo0ZpHh4eGqAtWrSozDbddNNNGqD9+eefRZ6/evWqNmLECM3FxUXz8fHR5s6dq02ePFkbMWKE8ZgBAwZos2bNMj4OCgrSPvjgA+PjyMhIrX///pqdnZ3Wtm1bbd26dRqgrV692njMc889p3l5eWkuLi7a2LFjtQ8++EBzd3c37i/t/RQ/z6FDh7RBgwZpDg4OmqenpzZ9+nQtJSWlyGdfuO2apmmzZs3SBgwYUOpn8+KLL2pdunQxPs7Ly9NeeuklrUmTJpqtra3WpUsXbe3atcb9X3zxhda1a1fN2dlZc3Nz0wYPHqzt379f0zRNW716tda7d2/Nzc1Nc3Z21vr06aNt3LixyLWCgoJKbUtGRoZ27733agEBAZqdnZ3m7++v3X333dqePXuKHFf8Z8xw27x5s/GYpKQk7cEHH9Q8PDw0T09P7d5779Wio6PLvHZp/9/M+f7WaZqmVW0IZHnJycm4u7uTlJRUZpemRVz4B74aDO7N4KnD6rlLEfDFAHD2gedOVe31hRCVlpmZSVRUFC1atMDBwaGmmyNEvVbW/zdzvr9liKc8WYWKtBkYclDSEiC7hmopCCGEEPWYBCjlKbwOj4FjI7DPj/wkUVYIIYSwOAlQylO4iqyBTieJskIIIUQVkgClPCX1oICqhQLSgyKEEEJUAQlQymPIQbFzLfq8IQ/l+rlqbY4QQgjREEiAUp7C6/AUJkM8QtQ5dXDSohB1jqX+n5kdoFy8eJGJEyfi5eWFo6MjnTp14p9//inSsBdeeAF/f38cHR0ZMmQIp04VnYp77do1JkyYgJubGx4eHkybNq3IMte1SuF1eAozDPFIuXshaj1DafD0dJl1J0RVM/w/M6ckf0nMKnV//fp1+vXrx6BBg1i7di2NGzfm1KlTNGrUyHjM22+/zYcffsiSJUto0aIF//d//0dYWBjHjh0zzoeeMGECsbGxhIeHk5OTwwMPPMCMGTNYvnx5pd5MlSgpSRYK9aBIDooQtZ21tTUeHh7GRdKcnJyMK/8KISxD0zTS09NJSEjAw8OjyEKLFWFWgPLWW28RGBjIokWLjM+1aNGiSOPmz5/P3LlzGTFiBADffPMNvr6+/Pzzz4wbN47jx4+zbt069u7dS8+ePQH46KOPuOOOO3j33XeLrGRZK2SXNsSTn4OSmQiZSeDgXq3NEkKYx8/PD8CslVyFEObz8PAw/n+rDLMClF9//ZWwsDBGjx7N1q1badKkCY8++ijTp08HICoqiri4OIYMGWJ8jbu7O71792bnzp2MGzeOnTt34uHhYQxOQK3BYGVlxe7du7n33ntvuG5WVlaR9RSSk5PNfqMVZuxBKTbEY+8CTl6QflUN8/h3rr42CSHMptPp8Pf3x8fHh5ycnJpujhD1kq2tbaV7TgzMClDOnj3LwoULefrpp/nPf/7D3r17eeKJJ7Czs2PKlCnExcUB3LDYkq+vr3FfXFwcPj4+RRthY4Onp6fxmOLmzZvHyy+/bE5TLae0acaghnnSr6pEWQlQhKgTrK2tLfYLVAhRdcxKktXr9XTv3p033niDbt26MWPGDKZPn85nn31WVe0DYM6cOSQlJRlvMTExVXq9IozTjEsIUKQWihBCCFElzApQ/P39CQkJKfJc+/btiY5WX9CGMafiS2zHx8cb9/n5+d0wBpybm8u1a9dKHbOyt7fHzc2tyK3aZJUyiwcK1UKRmTxCCCGEJZkVoPTr14/IyMgiz508eZKgINWT0KJFC/z8/Ni0aZNxf3JyMrt37yY0NBSA0NBQEhMT2bdvn/GYP//8E71eT+/evSv8RqpMdgmLBRpILRQhhBCiSpiVg/LUU0/Rt29f3njjDcaMGcOePXv44osv+OKLLwCVhPbkk0/y2muv0aZNG+M044CAAO655x5A9bjcfvvtxqGhnJwcHnvsMcaNG1f7ZvBoWunTjEGGeIQQQogqYlaA0qtXL1avXs2cOXN45ZVXaNGiBfPnz2fChAnGY/7973+TlpbGjBkzSExMpH///qxbt85YAwVg2bJlPPbYYwwePBgrKytGjRrFhx9+aLl3ZSm5maDlqe0Sk2Sbq/vr51UwI3UVhBBCCIvQaXWw9nNycjLu7u4kJSVVbT5K6mV4t7XafuE6WBUbEcvJhNfzZyw9dwacvauuLUIIIUQdZ873t6zFU5as/Hordi43BicAtg7g6q+2JVFWCCGEsBgJUMpS2jo8hUmirBBCCGFxEqCUpawEWYNGEqAIIYQQliYBSlnKqiJrILVQhBBCCIuTAKUsZVWRNZAhHiGEEMLiJEApiyk5KFILRQghhLA4CVDKYkoPilf+NORrZyE5turbJIQQQjQAEqCUpax1eAzcAiCwD2h6OLSyetolhBBC1HMSoJTFlCRZgG75lXQPLFUVZYUQQghRKRKglMU4xFNGDwpAh3vB1gmunoaYPVXfLiGEEKKekwClLKb2oNi7Qsg9ajtiaZU2SQghhGgIJEApiymF2gwMwzxHfoLstKprkxBCCNEASIBSFsMQT3k9KABB/aBRc9XrcuzXKm2WEEIIUd9JgFKWbEOAUk4OCoBOB10nqu2IZVXXJiGEEKIBkAClLMYhHhMCFICu4wEdnNsG16KqrFlCCCFEfScBSllMTZI1cG8KLQeq7YjlVdIkIYQQoiGQAKUs5iTJGnTLH+Y5uAL0esu3SQghhGgAJEApTV4u5GaobVNyUAyCh4ODOyTFQNTWqmmbEEIIUc9JgFIaQ4IsmNeDYusIHe9T2wekJooQQghRERKglMYwvGNtDzZ25r3WUBPlxBrISLRos4QQQoiGQAKU0pibIFtYQHfwCYHcTDjyo2XbJYQQQjQAEqCUpiIJsgY6HXTN70WRmihCCCGE2SRAKY05RdpK0nksWNnAxX2QcNxy7RJCCCEaAAlQSlOZHhQAl8bQJkxt//UOaJpl2iWEEEI0ABKglMacdXhK0/8p0FmrPJR//meZdgkhhBANgAQopTEmyVZwiAcgsBcMeVFtr3seLu6vfLuEEEKIBkAClNIYelAqOsRj0PcJaDcc8rLh+ymQfq3ybRNCCCHqOQlQSmOJHhRQM3ru+RQaNYekaPj5ESmBL4QQQpRDApTSVDZJtjBHDxjzjSr6dnIdbJ9f+XMKIYQQ9ZgEKKWpTKG2kvh3gTveUdt/vgpRf1nmvEIIIUQ9JAFKaSyVg1JY98nQ5X7Q9PDDg5Aca7lzCyGEEPWIBCilyapkobaS6HQw/D3w6QBpl1WQkpdjufMLIYQQ9YQEKKWxVJJscXZOKh/FzhWid8Da2ZY9vxBCCFEPSIBSGksmyRbn3RpGfgHo4J+vYc+Xlr+GEEIIUYdJgFIaSyfJFhd8R0ERt7Wz4cyfVXMdIYQQog6SAKU0xh4UCw/xFNbvSegyHrQ8+H4qXDlVddcSQggh6hAJUEqiaYVWM66iHhRQSbN3LYDA3pCVBMvHSqVZIYQQAglQSpaTrqYCQ9XkoBRmYw9jl4F7IFw7A6umysweIYQQDZ5ZAcpLL72ETqcrcgsODjbuHzhw4A37H3744SLniI6OZvjw4Tg5OeHj48Nzzz1Hbm6uZd6NpRiGd9CBnXPVX8+lMYxfCbbOELVVZvYIIYRo8GzMfUGHDh3YuHFjwQlsip5i+vTpvPLKK8bHTk5Oxu28vDyGDx+On58fO3bsIDY2lsmTJ2Nra8sbb7xRkfZXjcJTjHW66rmmX0cY9RWsvF/N7PFpDzdNr55rCyGEELWM2UM8NjY2+Pn5GW/e3t5F9js5ORXZ7+bmZty3YcMGjh07xtKlS+natSvDhg3j1Vdf5ZNPPiE7O7vy78ZSqqKKrCkKz+wJf0EqzQohhGiwzA5QTp06RUBAAC1btmTChAlER0cX2b9s2TK8vb3p2LEjc+bMIT093bhv586ddOrUCV9fX+NzYWFhJCcnc/To0VKvmZWVRXJycpFblarqKcZl6fekSprNSYc/X6v+6wshhBC1gFkBSu/evVm8eDHr1q1j4cKFREVFcfPNN5OSonoc7r//fpYuXcrmzZuZM2cO3377LRMnTjS+Pi4urkhwAhgfx8XFlXrdefPm4e7ubrwFBgaa02zz1VQPCqghpaGvq+2IZRB7qPrbIIQQQtQws3JQhg0bZtzu3LkzvXv3JigoiO+//55p06YxY8YM4/5OnTrh7+/P4MGDOXPmDK1atapwI+fMmcPTTz9tfJycnFy1QUpWDfagAAT2go6j4MiPsOG/MPnX6suFEUIIIWqBSk0z9vDwoG3btpw+fbrE/b179wYw7vfz8yM+Pr7IMYbHfn5+pV7H3t4eNze3IrcqZayBUsXXKcvgF8HaHqL+gpPra64dQgghRA2oVICSmprKmTNn8Pf3L3F/REQEgHF/aGgohw8fJiEhwXhMeHg4bm5uhISEVKYpllWV6/CYqlEQ9Mmfoh3+f1IbRQghRINiVoDy7LPPsnXrVs6dO8eOHTu49957sba2Zvz48Zw5c4ZXX32Vffv2ce7cOX799VcmT57MLbfcQufOnQEYOnQoISEhTJo0iYMHD7J+/Xrmzp3LzJkzsbe3r5I3WCE1mSRb2M3PgJMXXDkJ+xbXbFuEEEKIamRWgHLhwgXGjx9Pu3btGDNmDF5eXuzatYvGjRtjZ2fHxo0bGTp0KMHBwTzzzDOMGjWK3377zfh6a2tr1qxZg7W1NaGhoUycOJHJkycXqZtSK9SGHhQAB3cYOEdtb5kHmUk12x4hhBCimpiVJLty5cpS9wUGBrJ169ZyzxEUFMQff/xhzmWrX1b+NOaa7kEB6PEA7PlC9aJsew9uq2XBnBBCCFEFZC2ekmRXw0rGprK2gaH59VB2LYTr52u2PUIIIUQ1kAClJFmFSt3XBm2GQosBkJcNm16u6dYIIYQQVU4ClJLUliRZA50Owl4HdKo2yoV9Nd0iIYQQokpJgFKS2pIkW5hfJwi5W22f3lj2sUIIIUQdJwFKSYyF2mrJEI+BZ0t1n3G9ZtshhBBCVDEJUEpSk2vxlMWxkbqXAEUIIUQ9JwFKSWp6LZ7SSIAihBCigZAApbi8HMjLUtu1bYhHAhQhhBANhAQoxRmGd6B21EEpTAIUIYQQDYQEKMUZphjbOKgiabWJBChCCCEaCAlQiquNU4wNCgcomlazbRFCCCGqkAQoxRmGeGpbgiwUBChaXtGhKCGEEKKekQClOEMNlNqWfwJg66iGnkCGeYQQQtRrEqAUV9vW4SlO8lCEEEI0ABKgFFfb1uEpTgIUIYQQDYAEKMXV5iRZkABFCCFEgyABSnHZtThJFiRAEUII0SBIgFJcVi1OkgVw9FD3EqAIIYSoxyRAKa62rsNjID0oQgghGgAJUIrLriuzeBJrtBlCCCFEVZIApThJkhVCCCFqnAQoxRmTZGt7D4oEKEIIIeovCVCKkx4UIYQQosZJgFJcbV6LByRAEUII0SBIgFJcdh3qQZEVjYUQQtRTEqAUV1fW4snLgpyMmm2LEEIIUUUkQClkx+nL6Gv7NGM7F7CyUdsyzCOEEKKekgClkLMXE7BCDZtods413JpS6HSShyKEEKLekwClkBEd3ADI03TsjqnFwycSoAghhKjnJEApxJVMANJw5Nvd0TXcmjJIgCKEEKKekwClsPwpxqk4sP5IHAnJmTXcoFJIgCKEEKKekwClsPwE2TwbF3L1Giv3xtRwg0ohAYoQQoh6TgKUwvKnGDu7eQCwfHc0uXn6GmxQKSRAEUIIUc9JgFJYfg+Kh0cjvJztiEvOZOPxhBpuVAkkQBFCCFHPSYBSWH4OipW9K2N7BQKwdNf5mmxRySRAEUIIUc9JgFJYs1AY9jZ0m8j9vZuh08Hfp69w5nJqTbesKAlQhBBC1HMSoBTmGwK9/wXthtG0kRODg32AWtiL4uih7jMSa7IVQgghRJWRAKUME/sEAfDDvgukZ+fWcGsKkR4UIYQQ9ZxZAcpLL72ETqcrcgsODjbuz8zMZObMmXh5eeHi4sKoUaOIj48vco7o6GiGDx+Ok5MTPj4+PPfcc+Tm1qIv/0JuadOYZp5OpGTm8mvEpZpuTgEJUIQQQtRzZvegdOjQgdjYWOPt77//Nu576qmn+O2331i1ahVbt27l0qVLjBw50rg/Ly+P4cOHk52dzY4dO1iyZAmLFy/mhRdesMy7sTArKx0T+zQD4Jud59E0rYZblM8QoOSkQW5WzbZFCCGEqAJmByg2Njb4+fkZb97e3gAkJSXx9ddf8/7773PrrbfSo0cPFi1axI4dO9i1axcAGzZs4NixYyxdupSuXbsybNgwXn31VT755BOys7Mt+84sZHSPQOxsrDgWm8yBmMSabo5i7w7o1LbkoQghhKiHzA5QTp06RUBAAC1btmTChAlER6s1a/bt20dOTg5DhgwxHhscHEyzZs3YuXMnADt37qRTp074+voajwkLCyM5OZmjR4+Wes2srCySk5OL3KpLI2c77uocAMDSnbUkWdbKqlCirAzzCCGEqH/MClB69+7N4sWLWbduHQsXLiQqKoqbb76ZlJQU4uLisLOzw8PDo8hrfH19iYuLAyAuLq5IcGLYb9hXmnnz5uHu7m68BQYGmtPsSpsUqpJl1xyK5WpqLRlSkTwUIYQQ9ZhZAcqwYcMYPXo0nTt3JiwsjD/++IPExES+//77qmofAHPmzCEpKcl4i4mp3jVyujR1p1MTd7Lz9CyvLascS4AihBCiHqvUNGMPDw/atm3L6dOn8fPzIzs7m8TExCLHxMfH4+fnB4Cfn98Ns3oMjw3HlMTe3h43N7cit+qk0+l46OYWACzZeY7MnLxqvX6JJEARQghRj1UqQElNTeXMmTP4+/vTo0cPbG1t2bRpk3F/ZGQk0dHRhIaGAhAaGsrhw4dJSChY3yY8PBw3NzdCQkIq05Qqd0cnfwLcHbiSms3PBy7WdHMkQBFCCFGvmRWgPPvss2zdupVz586xY8cO7r33XqytrRk/fjzu7u5MmzaNp59+ms2bN7Nv3z4eeOABQkND6dOnDwBDhw4lJCSESZMmcfDgQdavX8/cuXOZOXMm9vb2VfIGLcXW2ooH+6telC+3nUWvr+EpxxKgCCGEqMfMClAuXLjA+PHjadeuHWPGjMHLy4tdu3bRuHFjAD744APuvPNORo0axS233IKfnx8//fST8fXW1tasWbMGa2trQkNDmThxIpMnT+aVV16x7LuqImN7BeJqb8OZy2lsjqzhVY4lQBFCCFGP6bRaU33MdMnJybi7u5OUlFTt+Sjz/jjO53+dpXcLT777V2i1XruIXQth3fPQYSSMXlRz7RBCCCFMZM73t6zFY6ap/ZpjY6Vjd9Q1DtZk4TbpQRFCCFGPSYBiJn93R+7uqgq3fbntbM01xNFT3UuAIoQQoh6SAKUCpt/cEoA/DscScy29ZhohPShCCCHqMQlQKqC9vxs3t/FGr8H/tkfVTCOMAUpizVxfCCGEqEISoFTQjFtUL8p3e2NISs+p/gYYApSsJMjLrf7rCyGEEFVIApQK6t/am2A/V9Kz81i6uwYWEXRwL9jOTKr+6wshhBBVSAKUCtLpdMZelMU7zpGVW83l761twD4/SJE8FCGEEPWMBCiVcGfnAPzcHLicksUvEZeqvwGOHupeAhQhhBD1jAQolWBnY8WD/ZsD8NmWM9W/iGBVzeTJy4XvJsFvsyx7XiGEEMJEEqBU0ribmuHtYs/ZK2m89OvR6r14VQUolw7A8V9h32JIu2LZcwshhBAmkAClktwcbFkwris6HazcG8NP+y9U38WrKkA5t61gO+6wZc8thBBCmEACFAvo19qbWYPbAPDf1Uc4FZ9SPReusgDl74JtCVCEEELUAAlQLOTxW9vQv7U3GTl5PLpsP+nZ1VCbpCoClLwciNld8Dj+iOXOLYQQQphIAhQLsbbSMX9cV3xc7TmVkMrc1Ueo8oWiqyJAiT0I2akFj+PqYICSm13TLRBCCFFJEqBYkLeLPR+O74aVDn46cJHv/4mp2gtWRYBiyD/x76Lur0RCbpblzl/V/p4P85pC9K6abokQQohKkADFwvq09OKZoe0AeOGXoxyPTa66i1VJgLJd3Xcep6rV6nPh8gnLnb84TYOrZ9S9JZxcD3lZcOZPy5xPCCFEjZAApQo8MqAVA9s1JitXz8xl+0nNqqJ8FEsHKHm5EL1TbTfvD36d1XZVDvPs+hQ+6g77l1jmfNfPqftrZy1zPiGEEDVCApQqYGWl4/0xXfF3d+DslTTeWltFPRCWDlAM+ScOHuDbUd2gahNlL+7Pv/ahyp8rJwNS8iv6Xj1T+fMJIYSoMRKgVBFPZzveG63yOJbviebs5dRyXlEBhgAlMxH0+sqf73z+9OKgfmBlBX75AUpVTjVOzg8o0hIqf67E6ILtaxYcNhJCCFHtJECpQn1be3NrsA95eo131kda/gKGtXg0PWRZINfFUP+keT91X7gHpaq+7JMvqvvUy5U/l2F4B9QKz+nXKn9OIYQQNUIClCo2+/ZgrHSw9kgc+85buKCajT3YOqvtyg7z5OXC+UL5JwCNg0Fnrc5tCCQsSa+HlFi1bYkelGtRxR7LMI8QQtRVEqBUsXZ+rtzXoykAb649bvnaKJbKQ4k7BNkpauaOoefE1gEat8vfXwV5KOlXIS+/Zomle1BAEmWFEKIOkwClGjx1W1scbK3Ye+464cfiLXtySwUohuGdZn3ByrrgeeMwTxXkoRTulclOUUmulWEIUKzt1b0kygohRJ0lAUo18Hd35MF+LQB4a90JcvMskNBqYMhDsVSAYhjeMTAmylZBD0rxYaPUSg7zXM8f4gkKVfcyxCOEEHWWBCjV5OGBrWjkZMuZy2l8/48FVzy2RA+KPq9o/ZPCfKtwJo9hBo9BWiWGeTStoAel9RB1Lz0oQghRZ0mAUk3cHGx5In/F4w82nrTcYoLGACWx4ueIO6RmAdm7g1+novsMj6+dhey0il+jJJbsQUmNh9xM0FlBiwHquWtnZaqxEELUURKgVKMJvYNo5unE5ZQsvtoWVf4LTGGJHhTD8E5QaNH8EwAXH3DxBTSIP1bxa5Tkhh6USgQohhk87k3Buy2gU0FX2pWKn1MIIUSNkQClGtnZWPFcmJoV8/nWM1xJtcAifBYJUPLX3wnqV/L+qkqUNQQohqnSlZnJYxjeadRczT5ya6Iey0weIYSokyRAqWbDO/nTuak7adl5fLjpVOVPWNkARZ8H53eo7eL5JwZVlShrGOIxDCNVpgfFGKCoZGS8Wqp7SZQVQog6SQKUamZlpeP5YcEALN8dTURMYuVOWNkAJe4wZCWBvVvB4oDFGRcNtGAPiqYV9KAEdFX3lclBKdyDAuDZSt1LoqwQQtRJEqDUgL6tvBnW0Y9cvcZDS/7hYmIl6n8YA5RSyrqnX4OfZsDuz1VvSXHn84d3mvUBa5uSz2Ec4jlqmTV/QAVUuZlq21+tWVSpfBHDFGNDgOKVH6BID4oQQtRJEqDUkHdGdyHYz5UrqVlMW7yX1KwKzuoprwdl58dw6DtY+29YfOeN5eBLq39SmFdrVfwsJ60gEKgsw/COc+OCfBFLDPF45g/xSA+KEELUaRKg1BAXexu+ntoLbxd7TsSl8MSKA+TpKzAltnCAUnxKbV4uRCxX2zpriN4BC/vBP/9Tx+r15eefgOpZ8WmvtuMtlIdiGN5xC1AzhaDiQzzZ6WqaMZTQgxIlU42FEKIOkgClBjXxcOSrKT2xt7HizxMJvPZ7BabxGgIUfS5kpxbdd2aTWozP0RNm7oag/qoXZM1TsHQknNoAmYlg5wp+Xcq+jiGR1VJ5KIYeFLcm4JwfoGQmQm62+ecy9J44uBd8Hh5BgE6V0K9MATghhBA1QgKUGtY10IMPxnYFYNH2c3y767x5J7B1LFh7pvgwz4Fv1X2XceDdBqb8Bre/CTYOcOZPWDFW7S8r/8TAGKBUQQ+KYyPVwwMVCyaKz+ABNdXYPVBtyzCPEELUORKg1AJ3dPI31kd56dej/HXSjC9pna7kPJTUyxC5Vm13m6TuraygzyPwr23QpEfBsWUN7xgYE2WrIECxslK5KFCxPJTiM3gMZKqxEELUWRKg1BKPDmzFyO5NyNNrzFy2n1PxKaa/uKQA5dBKNewT0B18Q4oe37gtPLgBhrwErW5VPSzl8e2g7pNiKr8wIUBS/npEhgRZl/wApSLF2orP4DGQRFkhhKizJECpJXQ6HfNGduKm5p6kZOUyddFe4pMzTXtx8QBF02B//vBO90klv8baBvo/BZNWg6ufCdfwAI9majv+qGntKkvhHhQoyEOpTA+KZ4uiz8tUYyGEqLMqFaC8+eab6HQ6nnzySeNzAwcORKfTFbk9/PDDRV4XHR3N8OHDcXJywsfHh+eee47cXAstnleH2dtY89mkHrTwduZiYgZTF+0lOTOn/BcWD1Au7IUrkWDjCB1HWa6BvhZKlC1cpM3Yg1KJmTylDfEYelCk3L0QQtQ5FQ5Q9u7dy+eff07nzjdWH50+fTqxsbHG29tvv23cl5eXx/Dhw8nOzmbHjh0sWbKExYsX88ILL1S0KfWKp7MdSx64CW8Xe47HJvPwt/vIyi2hwFphxQMUQ3Jsh3vUzBZLsVTJ+8wkNZsIwNVf3RtzUMwc4tHr4Xp+YvENOSiGIR5Z1VgIIeqaCgUoqampTJgwgS+//JJGjRrdsN/JyQk/Pz/jzc3Nzbhvw4YNHDt2jKVLl9K1a1eGDRvGq6++yieffEJ2dgWmmNZDzbycWPxAL5ztrNlx5irPfH8QfVk1Uhw91H3GdchKhSM/qcfdShneqShLLRpo6D1x9AQ7J7Vd0R6UlFjIywIrG3BrWnSfRxDorFQwZKiTIoQQok6oUIAyc+ZMhg8fzpAhQ0rcv2zZMry9venYsSNz5swhPT3duG/nzp106tQJX19f43NhYWEkJydz9GjJuQ1ZWVkkJycXudV3HZu489mkHtha61hzKJbXfj+OVlovQOEelGM/q3ooni0hqK9lG2XoQUk4AXkmDD2VpvjwDlQ8B8UwvOMeeONUaRs7mWoshBB1lNkBysqVK9m/fz/z5s0rcf/999/P0qVL2bx5M3PmzOHbb79l4sSJxv1xcXFFghPA+DguLq7Ec86bNw93d3fjLTAw0Nxm10k3t2nMu6NVAbX/bY/iy22l5FIYA5TEguTYbhPVFGRL8miuirrlZcGVSqzEbCzSFlDwXEVn8ZSWf2IgibJCCFEnlVOdq6iYmBhmzZpFeHg4Dg4OJR4zY8YM43anTp3w9/dn8ODBnDlzhlatWlWokXPmzOHpp582Pk5OTm4wQcqIrk1ISM7i9T+O88YfJ/BxdeCebk2KHmQIUC7uh5RLalijy/2Wb4yVlZpuHLNL1UMpPn3ZVMVn8EAlelBKmWJs4NlKFaWTHhQhhKhTzOpB2bdvHwkJCXTv3h0bGxtsbGzYunUrH374ITY2NuTl3ZjM2bt3bwBOnz4NgJ+fH/HxRfMBDI/9/Eqe7mpvb4+bm1uRW0My/ZaWTOuvptA+u+ogvx+KLXqAIUBJyf/ibzMU3PyrpjHGRNlK5KEULnNvYMhBSb+m1hAyVWlTjA28ZCaPEELURWYFKIMHD+bw4cNEREQYbz179mTChAlERERgbW19w2siIiIA8PdXX5ihoaEcPnyYhISCv5TDw8Nxc3MjJKSCf5E3AP+9oz13dwkgV68xc/l+3tsQWZA461gsUdnSybGFNQ5W91dPV/wcJfWgOHmpnh80SL9i+rnKG+KRqcZCCFEnmTXE4+rqSseOHYs85+zsjJeXFx07duTMmTMsX76cO+64Ay8vLw4dOsRTTz3FLbfcYpyOPHToUEJCQpg0aRJvv/02cXFxzJ07l5kzZ2Jvb2+5d1bPWFnpeH9MF3zd7PlyWxQf/Xma47HJfDC2K66FAxTnxtA2rOoaYljv5rqZawYVVlKAYmWtgpS0y2omjynF40CtVgxlBCiGcvf5U40tnZcjhBCiSli0kqydnR0bN25k6NChBAcH88wzzzBq1Ch+++034zHW1tasWbMGa2trQkNDmThxIpMnT+aVV16xZFPqJRtrK/47PIT3x3TBzsaKjccTuPfTHZzLKBTYdRkH1rZV14hGQeo+8XzFa4uUNIsHzM9DyUop6G0pLUBpFKQWIsxJV1OShRBC1Alm9aCUZMuWLcbtwMBAtm7dWu5rgoKC+OOPPyp76QZrZPemtGrswoxv/+F0Qip3fxHBPjsPbLOTqnZ4Bwqm7WanqnwRZy/zXp+VAllJart4noxLY0jA9Jk8hl4cR8/SC9JZ26oS/dejVKJs4V4bIYQQtZasxVNHdQn04LfH+tO9mQfJmXmMSX2a37suRPNuW7UXtnUoqP5qyP8wR3J+L4a9O9i7Ft1nbg9KeTN4DCRRVggh6hwJUOowHzcHVszow5ieTTmgb83MXW68uuZ42VVnLcHDMMxzzvzXJhtWMS6hJ8PcarLlzeAx8JRaKEIIUddIgFLH2dtY89aozswd3h5QBd2eWXWQnDx91V3U0GNRkUTZkhJkDcxdj6e8GTwGxjV5JEARQoi6QgKUekCn0/HQzS35YGwXbKx0rD5wkRnf/ENGdjmLDFZU4URZc5UVoJjbg1LeDB6DwjN5hBBC1AkSoNQj93ZrypeTe+Jga8XmyMtM/Ho3ielVsACjYYinQj0oJRRpMzDmoJjbg1LeEE+hAEVfhT1LQgghLEYClHpmULAPS6f1xs3Bhn3nrzP2813EJWVa9iKGHpQKJcmW1YNixhCPPg8So/Pb07zsYz2C1GrHuZkF1XaFEELUahKg1EM9m3uy6uG++LrZExmfwqiFOzh7OdVyFzD0oCRdUIGCOUqrgQKFelCulN/TkXwR9DlgZVv+1GFrm4I2yzCPEELUCRKg1FPt/Fz54eG+tPB25mJiBiMX7mDX2auWOblbgAoM9DkFAYepSlrJ2MDZW91reZBxrezzGId3glQV2vJIoqwQQtQpEqDUY4GeTqx6OJSugR4kpucw6evdfL83pvIntrIGj/yCbeYkymanQ8Z1te1eQg+KtW3BukLlJcqaOoPHQKYaCyFEnSIBSj3n7WLPyhl9uLOzPzl5Gv/+8RDz/jhOXmVrpVQkUdZQat7OBexLWZHa1GJtZgco+YmyV2WIRwgh6gIJUBoAB1trPhrfjVmD2wDw+V9neXjpPtKycit+0ookyhYe3ilt0T7jVONyEmWNU4zLmcFj4GWYySM9KEIIURdIgNJA6HQ6nrqtLQvGdcXOxorwY/Hc99lOLiVmVOyEHhWohVLWDB4DY7G2qhriiZKpxkIIUQdIgNLAjOjahBXT++DtYsfx2GRGfLKdHWeumH+iilSTLasGioGpxdrMDVA8moG1HeRlQZIF8nCEEEJUKQlQGqAeQY34eWY/2vm6cjkliwlf7WbeH8fJyjVjynBFqsma1YNSxhBPZlLBLB9TAxQr64JelCunTHuNEEKIGiMBSgPVtJETPz3al/E3BaJpKi/lnk92cDI+xbQTeDRX9ymxkGNiIThTAhRTelAMvSfOjcHexbRrA3irHByunDT9NUIIIWqEBCgNmLO9DfNGduaLST3wdFZDPnd+9DeLtkeVvyKyk6eajQMFFV3Lk2RYybiMIR5TZvEkHFf3hpk5pvJuq+4lQBFCiFpPAhTB0A5+rHvyZga2a0x2rp6XfzvGlEV7yi6Rr9MVDK+YOsxjUg9K/hBPWbN4zv2t7gN7m3ZdA2OAIkM8QghR20mAIgDwcXVg0dRevDqiA/Y2Vmw7dYVb3t7MzGX72RyZUHLdFA8zphrnZEJ6fjKuST0ol0ErpRfn3DZ13/zm8q9bmAzxCCFEnWFT0w0QtYdOp2NSaHNCW3nx7x8OsT86kd8Px/L74Vh83ewZ2b0po3s0pWXj/KEdcxJlDUXabBwKqsWWxJAkq89RVWedPIvuT4xRAZHOGpr1Mev9GQOUtAR17rLaUR5Ng61vg3tT6Dah4ucRQghRIulBETdo7ePKT4/24/cn+jO1b3M8nGyJT85i4ZYz3PreVkYt3MGRi0nmVZMtPLxTWpE2AFsHsHdX2yXN5DEM7wR0BYdSqtGWxt4VXPOHl66cNu+1xV2OhC1vwK+PQ3Js5c4lhBDiBhKgiFJ1CHDnpbs7sPs/g/l0QncGtWuMlQ72nb/O1EV7uGrnrw40ZYinrFWMizPmoZSQKGsIUMwd3jGw1DCPITFYy4OIpZU7lxBCiBtIgCLKZW9jzR2d/Fn0wE3snDOY9v5uXEnN5v+25k9JNmWIp6xVjIsraybPub/UfYUDFAvN5Clc7G3fN1KdVgghLEwCFGEWXzcH47TkzfGO6snMJMhILPuFpszgMShtJs/186rnoiL5JwaWmsljCLgAkqLh7J+VO58QQogiJEARZgv0dOLTCd3JsXLkspafB1JeL4opZe4NSutBMQzvNOluXoG2wiw1xJOU/35sndX9vsWVO58QQogiJEARFdKnpRcv3hXCBU0FE0eOHir7BWbloJRSTbay+SdQ0INyPQrycip+HkPA1ftf6j5yLaTEVfx8QgghipAARVTYxD5BWOVPNV739y7OXE4t/WBzhnhKWo9H0wrVP+lfgdZScH1bZ9DnqpWNK8pQFbf1EFUwTp8LEcsqfj4hhBBFSIAiKkyn09GxYxcAfHLjmf7NPyRnltArkZcDqfFqu6I9KInnVWKqlU3F809Uoys/zKNpBQGXexPoMVVt71siybJCCGEhEqCISrH2bA5Aa7urnL2cxhMrDpCUXixISYkDNLC2Ayev8k9auJqsQVR+70mTHmDnXLlGV3YmT9oVyMsCdKquSsg9qnZL4nmI2lK5tgkhhAAkQBGVlT/E0901GXsbK7ZEXqbvm5t444/jxCfnr+VzYU/+sc3ByoQfucJ1UAzl7i2Rf2JQ2Zk8yfnDOy6+YGMHdk7QZax6riqSZRNOwO/PQNpVy59bCCFqKQlQROXkV5N1SLvA/6b0INjPlbTsPL746yw3v7WZ5388RNo/K9Wx7e827ZyGHpS8LMhKtlz+iYFhiOdqBQMUwwwe90LDVYZhnhO/l1xgrjK2vgV7v4Lt8y17XiGEqMUkQBGV494UdFaQm0k/3zzWzrqZRVN7cVNzT7Lz9Pyx9zi2UZsAOOM/zLRz2jmBXf404rQrasZN8kWwsjV/BeOSFB7iKW1BwrKUNGXatwM07VU1ybIJx9X9Gam1IoRoOCRAEZVjbauCFIDE8+h0OgYF+/D9w6H88HAozzQ9gZ0uj+P6ZoQtTWD+xpPk5JmQSOpcaJjHkH/StKcKXirLs6UKqjKTSl7vpzyGGTyG921QFcmyeTlwNX/doPgjMpVZCNFgSIAiKq+URQN7NvdkisteAI55DyVXrzF/4ynu/XQ7J+NTyj6nS6FibZbMPwG1IKGhzRVJlC2t6FyHe8HeTfX4GEryV9a1KLWys8GZzZY5rxBC1HISoIjKy0+UvaGabPIlY3AxctITLBjXFXdHW45cTObOD/9m4ZYz5OlLGWIp3INiyfwTg8pMNTb2oBQLUOycofMYtW2pZNnLJ4o+lmEeIUQDIQGKqDyP5uq+WA8KR1cDGgT2QdcoiBFdmxD+1C0MDvYhO0/PW+tOcN9nOzhbUoE3Qw9K9C5IiVVTlANvslybKzOTx5Ak69b0xn2GYZ7ja25cS6girkSqe0OPz9nNUmtFCNEgSIAiKs/Qg3L9XNHnD69S953uMz7l4+bAV1N68vZ9nXG1t+FAdCLDFmzjm53n0AonrBpm8kSuVfdNe4Gto+XaXNEeFH2eCpjgxh4UAL9OqlaLPgcOraxcGwEu5wco3SaqCrhplyH+cOXPK4QQtZwEKKLyGjVX94WHeK6egUsH1MrDHe4tcrhOp2NMz0DWPXULN7fxJitXzwu/HGXakn+4kpqlDjLUQslJU/eWyj8xqGixtpQ40PJURVsX35KP6TBS3Ufvqnj7DAxDPH6doEX+ZyDDPEKIBkACFFF5huGH5IsFC/Ad/kHdtxoEzt4lvqyJhyPfPHgTL94Vgp2NFX+eSOD2+dvYEplQ0INiYMn8EygIUBJjIDvd9NcZEmRd/cHKuuRj/Dur+7hK9nTo8wqGoBq3g1aD1fbpTZU7rxBC1AGVClDefPNNdDodTz75pPG5zMxMZs6ciZeXFy4uLowaNYr4+Pgir4uOjmb48OE4OTnh4+PDc889R25ubmWaImqSiw/YOIKmV+vlaFqh4Z3RZb5Up9PxQL8W/PpYP9r5unIlNYupi/bydURawUHW9mqIx5KcvMCxEaDBtTOmv86QIFvWmkK+HdV94nk1lbmiEs9DbibY5M86anWrej56F2Snlf1aIYSo4yocoOzdu5fPP/+czp07F3n+qaee4rfffmPVqlVs3bqVS5cuMXLkSOP+vLw8hg8fTnZ2Njt27GDJkiUsXryYF154oeLvQtQsnQ48mqnt6+ch9qCq0mrjAMHDTTpFsJ8bvzzWj6l9mwPwzeFCvRqBN6mpwZZuc0WGeQw9KMVroBTm5FmQQBt/tGLtg4L8E682qrfGqxW4N1P5LYap10IIUU9VKEBJTU1lwoQJfPnllzRq1Mj4fFJSEl9//TXvv/8+t956Kz169GDRokXs2LGDXbvUePyGDRs4duwYS5cupWvXrgwbNoxXX32VTz75hOzsbMu8K1H9CifKGnpP2t4O9q4mn8LB1pqX7u7Aogd6oTk1Nj6/LTeYtKwq6GEzJsqaMZOnpDL3JfHL70WpzDCPIUBp3E7d63TQOr8XRfJQhBD1XIUClJkzZzJ8+HCGDBlS5Pl9+/aRk5NT5Png4GCaNWvGzp07Adi5cyedOnXC17cgwTAsLIzk5GSOHi35r82srCySk5OL3EQtY0iUvR4FR35S2+UM75RmUDsffnpyKFk61Wvy0Rk/Br+3lV8iLhad6VNZFepBMQzxlNGDAiqpFSwUoAQXPGcY5pE8FCFEPWd2gLJy5Ur279/PvHnzbtgXFxeHnZ0dHh4eRZ739fUlLi7OeEzh4MSw37CvJPPmzcPd3d14CwwMNLfZoqoZEmUP/wgpl8DeHdrcVuHTebs6YHfb/3Gh5TgSPLoSl5zJrJURjP1iF8djLRSgViRAMbUHxdcSPSj5M3gMPSgALQaoMv1XT0FidMXPLYQQtZxZAUpMTAyzZs1i2bJlODhYOCegDHPmzCEpKcl4i4mJqbZrCxMZhngMPQwhd4GNfaVOqev7GE0nf866pwfx7NC2ONhasSfqGsM/3MYLvxzhelolhwSNAcpp04uflVbmvjhDD0rCccirwPCUppXcg+LoAU16qm0pey+EqMfMClD27dtHQkIC3bt3x8bGBhsbG7Zu3cqHH36IjY0Nvr6+ZGdnk5iYWOR18fHx+Pn5AeDn53fDrB7DY8Mxxdnb2+Pm5lbkJmoZQw+KQQWHd0riYGvNY7e24c9nBjK8sz96Db7ZeZ7QNzcx56dDRMaVs65PaTyC1ArJuRkFgVVZcrMgNf9nt6wkWYBGLdSKzHlZBYv9mSPpgqoBY2ULni2K7mudP934jAzzCCHqL7MClMGDB3P48GEiIiKMt549ezJhwgTjtq2tLZs2FfzijIyMJDo6mtDQUABCQ0M5fPgwCQkJxmPCw8Nxc3MjJCTEQm9LVLtGhQIUF1/LF1YDAjwc+eT+7iyf3puOTdzIzNGzYk8MYfP/4v4vdxF+LL70tX1KYm2jZsaAacM8yZfUvY2DmqZcFisr8O2gtisyzGOcwdNKrRhdmCEP5ewWVStFCCHqIRtzDnZ1daVjx45FnnN2dsbLy8v4/LRp03j66afx9PTEzc2Nxx9/nNDQUPr06QPA0KFDCQkJYdKkSbz99tvExcUxd+5cZs6cib195YYERA1ycFd1RTKuq0qqpRUxs4C+rbz57bH+7D13nUXbo1h/NI4dZ66y48xVAj0dmRLanEmhQdjbmNAG7zYq1+PKKWg9pOxjjcM7AWpGTXl8O0LM7vzS9Gb2KJWUf2IQ0F3l+GQmwcX9EGjhGjFCCFELWLyS7AcffMCdd97JqFGjuOWWW/Dz8+Onn34y7re2tmbNmjVYW1sTGhrKxIkTmTx5Mq+88oqlmyKqW1A/VVSt28Qqv5ROp+OmFp4snNiDbbNv5V8DWuLuaEvMtQxe+/04Yz7fxcXEjPJPZE6ibJKJ+ScGlZnJc6WE/BMDaxtoOUBty3RjIUQ9ZVYPSkm2bNlS5LGDgwOffPIJn3zySamvCQoK4o8//qjspUVtM+or9Ve9a8m5RFWliYcjc4a158nBbfnpwAXeXhfJwZhE7vxwGwvGdeOWto1Lf7E5qxob8lTKyz8xMAYoR0w7vrDiNVCKa3UrHP9V5aEMnG3++YUQopaTtXiE5dg6VntwUpijnTUTegex5vH+dGzixvX0HKYs2sOCjafQl5abYs6qxub2oPi0B3SQlgAp8eUebqRphYZ4SuhBgYI8lAv/QEai6eeuCts/hCV3QdrVmm2HEKJekQBF1DuBnk788HBfxt/UDE2DDzae5MEle0ueluyVH6Ckxpf/RW9KmfvC7JzBq7XajjdjmCc1XvVE6awKXl9coyC1T8uDc9tMP3dV2PEhRP0FOxbUbDuEEPWKBCiiXnKwtWbeyE68c19n7G2s2BJ5mTs/+pu9564VrUbr4KZWJobypwMnmRmgQKGS92YM8xh6Txq1KLuWTG2oKpt+DdIuq+09X6nHQghhARKgiHptdM9AVj/ajyAvJy4mZjD6s50MfHcL8/44zoHo62rox9RhnmQTVjIuriKJsiUVaCtJq/x6KKc3qRotNaFw7k5OGuxaWDPtEELUOxKgiHovJMCNXx/rz8juTbCzseL81XQ+/+ss9366g75v/smeFG8A9JfLCFCy09UUaii/zH1hvvkBSrw5PSjlJMgaNO8PNo6QFA2f3wIxe0y/hqUYZhvZ5xdP3P25Gp4SQohKkgBFNAjujra8P6YrB/7vNj65vzt3dQnA2c6auORM1sSqFZf37tzCF3+dISk958YTGPJP7FxVzRdTGXpQrpyEHBOmPYPpPSj2LjBmCTg3VsNCXw+FP/4NWRWsrFsRhrZ2Gafam5UEe76ovusLIeotCVBEg+Jsb8Pwzv58NL4b+/7vNv43tSfu7QcB0CXvCO/9cYje8zYy56fDRUvoJxmmGJvRewJqVpOTF2h6tS6PKcoq0lZc2zCYuQe6TgA02PM5fBoKp8LNa2dFGYZ4GgfDzc+q7Z2fQlZq9VxfCFFvSYAiGiwHW2tuDfblmQn3oLkG4KDLYbRXVH4J/WjC5v/FuC92su5ILLmJ+QtUmpN/AqrirJ8ZwzxpVyD9CqArqNFSHidPuOdTmLQaPJpBUgwsuw9+nF71SauGIR7vttBxJHi2goxr8M//qva6Qoh6TwIUIXQ6dG1uA+DVDrF8N6MPwzr6YW2lY9fZazy8dD9f/66m8ibZ+Zh/fl/DTB4TEmUNQyYegWDnZN51Wt0Kj+6CPjPVFOXD38Paf5t3DnPkZMD182q7cTu1vMHNT6vHOz4yfUhLCCFKIAGKEAD5AYru9EZ6t/RSJfT/PYhHB7bC28UO92y1uOXXh3K499PtrNgTTUpmCbkqJTGnomx5BdrKY+cMt78B45arx6c3qsJvVeHqGUADBw+VBwPQeSy4N1PF6fZ/U7Hzrn5Y5dPkZFqqpUKIOkgCFCEAWgwAK1u4djb/i1etnvzv24PZOWcwQ5rkAhCn8+JAdCJzfjpMr9c3Mv2bf/j4z1NsPXmZayUVgoOiQzzlBQumzuApT6vBatXljOvl13epqMLDO4bFE61tof+Tavvv+eZPf05NgIMr1CKLF/ZaqqVCiDqo0mvxCFEvOLhBsz6qKuupcPBqZdxla22Fd54qRjZn3GBaXW3N9//EcOZyGuHH4gk/VlDGvomHI52butO5qQcjugYQ4OGovsCt7SArGRLPQ6PmpbejrEUCzWFjp1Y9jt4B0bsKar1YkmFaduNiuTLdJsJf70DKJYhYDj0fMP2c0TsLti8dgBY3V76dQog6SXpQhDDIH+bhdLEZMJpmnGbcyK8V/xrQio1PD+Dnmf2YO7w9I7oG0NLbGYCLiRmsPRLHW+tOMOCdzcz+4RBR17MLAo7y8lBMnWJsisCb1H3M7sqfqySGwnbexXp7bOyh3yy1/ff7kGfiUBjA+UIBSmxEpZpntO19tV6QEKJOkR4UIQxa3wbhL8C5v1WCp62jej4zCbLzp826BQCg0+noGuhB10AP48uTM3M4cjGJQxeS+PN4AnvOXeO7f2JYtS+G5Y0D6MMhlYfS/q6Sr5+RCCmxatvUGTxladYHtlN1BdyMAUoJbe0+Bba9B4nRcHgVdL3ftHNG7yjYvnSg8m28egY2vay2O9yrko+FEHWC9KAIYeDTHtyaQm6mClIMDEXaHD3LnFnj5mBL31bePDygFd8/HMqPj4QyONgHvQbrr6ok0v17t7HvfClTfw1f+K4Basipsprm96BcibT8dGN9XqEaKCUEKHZOEPqY2t7xkWnnzEwu2sN07WzlV2qO+qtg+/z2yp1LCFGtJEARwkCngzZD1HbhQmfGRQLNq4HSI8iTr6f24o8nbsajZXcAGqeeZNTCndzzyXZ+O3iJ3Dx9wQvMKdBmCmevgtWQLZ1wmhgNeVlgbQ8eQSUf02Mq6Kwh4RhcP1f+OS/sUQXtPIIKzhl7sHLtLBygRNXwqs9CCLNIgCJEYa3z81BObSh4zrhIoBmrGBcSEuDGrPvvBSDQ6jJe1hlExCTy+IoD3PL2Zj7feoakjBzL5p8YBPZR95bOQzH09ni1VvVPSuLooYaZwLTKtob8k6B+ENBNbVdmmEfTVNKzwTkJUISoSyRAEaKwlvnTja9HGacbV7QHpQjHRuCu8h82TfRm1uA2eDnbcSkpk3lrTxA6bxOnjvyjjrVUDwoUJMpGWzhAMQZT5eTKtM7vkTq9sfxzGmbwBIVaJkC5fALSLqvp1jprNYMqMbri5xNCVCsJUIQozN5VfUFCwV/9hnV4zC1zX1x+PRSP5Eieuq0t25+/lbdHdaadryvp2Xk4Jqt6JZ8etSHmWnrlrmVg6MG4uM+82TTlKStBtrA2Q9X92a1lF17LzYIL+QFas74Q0FVtVyZAMQzvNAuFJmqIrUhukRCiVpMARYjiWhebbmxIknWv2BCPkbHk/SFArQU0plcg6568meWTO9JUdwWAL47bMujdLTz/46HKBypebVSl19wM00rtm8rUAMW3g0r6zc2A82UEBxf3q5wW58aqBo1/F/V84vmKJ/gaApQWt0Dz/mpbAhQh6gwJUIQozlAP5dzfkJ1uwR4UQ4CSX/I+NwvObkEX/gJ9N48FIMfBm05tWpCr11i5N4ZB725hzk+HuXC9goGKlZXl66FomukVb4skHpcxzGOYXtwsVL3GsRF4tlTPVaQeij6vIOekxS3QPL/gmyTKClFnSIAiRHGNgwtNN94GyZfU85XJQYGCkvcJx2DZGHirOXwzAnZ8CJePAzpse07m22m9+fGRUG5u402uXmPFnmgGvbuFp7+P4NilZPOvG9hb3VsqQEm7ApmJgK5gllBZDMM8hROPizMmyPYteM6/q7qvyDBP3GFVv8bOVZ0nsDdY2UBSdMECh0KIWk0CFCGKK/xX/8GVaugBnRqqqAyP5uoLMy8bTq2HnHRw8YUu98Oor+G5MzDkRUBNUf52Wm9WPRxKv9Ze5ORp/LT/Ind8uI2JX+1mc2QCer2JiwAaApTo3ZZZONBQjt+jWUExu7K0GKCCg2tnChKPC9PnFQRPzUILnq9MoqxheKd5P7C2AXsXVfofZJhHiDpCKskKUZI2Q2HfYjj+m3rs4qvWt6kMKysY+gqcXK++iFsPUTkahoX2StCruSfLHupDREwiX207y9ojcfx9+gp/n75Cax8XHurfgnu6NcHBtpSpvqASRHXWam2cpAuVr6ZqyD8xdbaRg5t6v+e2qdk8hdY5AiD+qFqnyM61oJcJCgUoFaiFUjj/xKDFzarWyrlt0G2C+ecUQlQr6UERoiQtblHTjfX5M18qO7xj0PNBuP87teKvX8cyg5PCugZ68PH93dn63EAe6t8CF3sbTiek8nz+qsqPrzjALxEXVT2V4uycwb+z2rbEMM9lExNkC2tTQn0ZA8P04sCbitZUMSTKJkWrYSVT5eXA+fyclsIBSuFEWUv0JAkhqpQEKEKUpPB0Y6h8gqyFNG3kxNw7Q9gx51bmDm9PEw9HUjJz+e3gJWatjKDHq+FM+GoXi7ZHFZ0BZMk8FMMQj1kBSn4eiiHxuDBDMFH48wbV82LIcbkUYfq1Lu6HnDS1NIFPh4LnA3uroDMpRs0OEkLUahKgCFEaw3RjqPwUYwtzc7DloZtb8te/B/HjI315ZGAr2vi4kKvX2H76Ki//doyb397MpK93c+RikmVn8hjX4DGjoFzjYFWorvg6R5pW0IPSrO+Nr6tIHso5Q/5JfzWsZmDnDE16qG2ZzSNErScBihClMfzVD7WmB6U4aysdPYIaMfv2YMKfHsCWZwcyd3h7+rT0xNpKx7ZTV7jzo7+Zu89FvSDuCGSlVvyCWamqBwLM60HR6QpVlS1U9v7aWUiNB2u7guChMEOAYs5U45LyTwykHooQdYYEKEKUpnE7Y3n6SieWVpPm3s48dHNLVs4IZfMzA7m3WxN0Olh6PJdLmhdoeVw/tbPiF7ia33vi5A1Onua9tvB0Y0MOiGF4J6A72Drc+Bpze1ByMgvK+rcYcON+U/NQUuLhzGbTrimEqBISoAhRGp0O7pwPPadB29trujVma+blxAdju/L74zczqF1j/tGrHo8l33/PvLXHOXYpGa3wl3RmEiy9D36eWfqXd0WGdwxa3KJ6Sq6fK5huXHj9nZL4dQZ0qppvSnz517iwR00Ld/ED7zY37jfkoSRfUOstlSQ7Df4XBt/eI0GKEDVIAhQhytJmCNz5PtjY13RLKiwkwI1FD9xE5z6qB6OLFsnnW89yx4fbCJ33J8//eIj1h2LIXTlJDb9ELIWT60o+maGCbElf/uWxdykoxGaYzWPoQSkp/8TwGsNQkinDPIWHd0qaIWXnBE17qu3Shnk2vVoQvBz/tfxrCiGqhAQoQjQQzbsNAqC/QxSD23njYGtFXHImK/dGk/j9Y9ic22o8NnvDK6DX33gS4wyeCq64XHiYJyUuPxDQFSTxlsQ4zBNR/vkNya8tbi79mLLyUM7vhN2fFTw+uV6mJAtRQyRAEaKh8O0Etk7Y5iTz9XA3Il4YypIHb+Lrln8x1mYLeZqOJ7MfJVlzxO7qMV575w3eWneCfeevF1StNQzxmJMgW5hhZtT57apoG6hFFB09Sn+NqXkoWalwMX9F5JISZA0Kr8tTOPjITodfZgIadBoNtk5qaCn+SNnXFUJUCQlQhGgorG0KZsrE7MbB1poBWVsZfOlzAK4PfJ3Od8xgvftoAManLeWLLScZtXAHN72xkTmr9qM35I40rmCA4t0GPIJUuf9t76nngkoZ3jEI6KruywtQoneBPleV4G/UvPTjmvZSuTApl9QsIoPNr6ty/K7+cMe70HKger604S5LSLsCC/urYaX64tIBWNAV1jxds+04s1lma9VxEqAI0ZAUXpfn/E74+RH1OPQxvAfN5MH+LRj96OvoHT1pZRXLy82P4Gpvw5XUbHbv34eVPocM7Fl0JIek9BKq1pZHpyuoKmsIDkpLkDXw6wQ6K0iNg+TY0o+Lyh+iKqv3BFQeSpNieSgxe2DnJ2r7rgWqR6dtmHp8cn3Z56uM479C/GH4+32VPFzXnd8BS+5WQ3f7l0BmBRa3tITYQ/DtvfDtSMi4XjNtEJUmAYoQDUmzPur+zJ+w8n7VkxF8J9xW6C94Bzes+j8FwMSMFeybcwtLp/Vmatts9VK9Py+vOUHveRt5btVBImISi84GKk/h+jJQeoKsgZ2zKvQGZSfKnjPkn5Qwvbg4Yx7KNjU12TC002V8QWBiaOeFfyD1cvnnrAjDKs6aviBAqqtOb1QBQVZ+UKLPLUharm5/vgpoakbX2a3lHi5qJwlQhGhIDDNYUuMg45oa8hn5ZdGKqwA3TVdTdZOisTu0lP5tvJncOgsA5yYhBPu5kpmjZ9W+C9zzyXaGLdjGgo2nOB6bXH6w0vxmsM6fFeXZElx9y2+3f1d1X9owT8Z1iD1YcP7yGJJoz/0NW95QCyC6+ELYGwXHuAXkrwekFS0uZ0nRhWrS7P8W0q5WzXWq2rFfYPk4yM2ANmHQfbJ63pBnVJ3O7yy65lNNtEFYhAQoQjQkjo0KeiM8msH4lWrIozhbR7jlWbX91zsqgTR/FeMWwd1ZO+tmfnykLyO7N8HOxooTcSl8sPEkwxZs4+a3N/PKb8fYeeYquXklzASycyrowSiv98SgvETZ8ztUL4RXG3DzL/98xjyUWNi+QD135wc3Fp8z1L+pijyUxBhVlVdnDT4h6st975eWv05Vi1gOq6aqhTU73Atjl6peOYAzm6p3FpSmwaaX1Xbj9vlt+FNmYtVRZgUoCxcupHPnzri5ueHm5kZoaChr16417h84cCA6na7I7eGHHy5yjujoaIYPH46TkxM+Pj4899xz5ObmWubdCCHKd/Ozqpdhwg/g4lP6cd2nqCAmNV59cV4xrGLcBp1Oldh/f0xX9vxnMG/f15kh7X2xt7HiwvUM/rc9ivFf7qLn6xuZ89OhG4eBbnlOBQl9Hi752sUVDlCKf9kkx8Julehbbv6Jga2jur5Bp9EQPPzG4wzDPaf/hNxs085tKkPviX/ngmBwzxc3LqZYm+3+QuUxaXrVazLqa7CxUwGotR0kRsPV09XXnlPh6nO1cYBxy9R98kW4fKL62iAsxsacg5s2bcqbb75JmzZt0DSNJUuWMGLECA4cOECHDmrV0OnTp/PKK68YX+PkVPDXWV5eHsOHD8fPz48dO3YQGxvL5MmTsbW15Y033rjhekKIKtB5tLqVx8YOBjwPvzwKf38AeflJscWqyHo42TGmZyBjegaSnp3LtlNX2HA0nj9PxHM9PYcVe2JYsSeGYD9Xxt/UjHu6NsE9KBQeKtr1npyZw+ELSRy8kIirgy1jejbF3sZa7fTrqHoa0i5D8iVwbwI5GbDjY9W2nDRAB53uM/1zaH6zmu7s3BiGvV3yMf7dwNkH0hIgekfBzB5LKFykrv0INbsp8TxELFNDbJa2/xv4Z5Ea1ms5UAURZU3vLs+uhbDuebXdZyaEvV5QHM/OGZqFqsTl0xsrVtjPXHo9bMr/7rlpOni1gqB+qhfn9CbwaV/1bRAWpdPMym67kaenJ++88w7Tpk1j4MCBdO3alfnz55d47Nq1a7nzzju5dOkSvr5q3Pmzzz5j9uzZXL58GTs7O5OumZycjLu7O0lJSbi5uVWm+UKIsuTlwqd9Ctbg0VnDf2NNqqybm6dnT9Q1vv8nhj+OxJGdq4Z77G2sGN7Jnzs6+ROblMGBmEQOxiRy5nJakdcH+7ny/piuhATk/x9f2E/VJBm7FHKzYONLBQsXNu0FYfMgsBcmS7sK4f+neoqa9S79uF9mwoGl0OdRuH2e6ecvzye91V/2Y5dC+7tgz5fwx7NqivRj+9S0cEtJiYcPu0JOod4ZnZXqmWo5UN0C+6ig1BTZafBOGxUYDpgNA+fcWLl3+4fq8219G0z8wUJvpAyHf4Afp4G9G8w6qIbrdn4C6/8DLQfB5J+rvg2iXOZ8f1c4ByUvL4+VK1eSlpZGaGjBNMFly5bh7e1Nx44dmTNnDunpBf8hdu7cSadOnYzBCUBYWBjJyckcPXq01GtlZWWRnJxc5CaEqAbWNjDoPwWPGzU3uey/jbUVfVt7M39cN/b+Zwgv3aWSa7Ny9fx04CIPffMP//fLUX7af9EYnAR6OjK8kz+eznaciEthxCd/8/Gfp1Qui6Eeys+Pqi+ipBhwa6qGFaaFmxecADh7wT2flh2cQEEeSuRay+UypF8rGHZolv/7s+sEcPRU040tXWJ/23sqOPHtBL2mq1wdTQ8X96l9S+6Cb0aUXD24JCd+V8FJoxYlBydQsHr1ub9Vb1dVystRdWwA+j5ekEtkaMP5HXVr6EwAZg7xABw+fJjQ0FAyMzNxcXFh9erVhISEAHD//fcTFBREQEAAhw4dYvbs2URGRvLTTz8BEBcXVyQ4AYyP4+LiSr3mvHnzePnll81tqhDCEkLuAd/3Vb2OiiwSCLg72TK1Xwum9G3OwQtJrNwTza6zV2nu7UyXph50DfSgc1N3vFxU8HMlNYv/rj7M+qPxvLvhJOHH4vkyJAQfUNNYbZ2h/1MQOrPkJF9Lajkwf5HDKJVPYYnhCkP+iXc7cPZW23ZOcNMM2PqmStztcG/JX/zmun4e/vmf2g57HVrmT8NOuqCm4J7dAsd/U0NYZ/8s+FIvy8EV6r7LuNLb6NMeXANUQbzzO6D14Eq/lVIdWKrq6jh5Q59HCp73bquC2OQLajjPUINH1AlmByjt2rUjIiKCpKQkfvjhB6ZMmcLWrVsJCQlhxowZxuM6deqEv78/gwcP5syZM7Rq1arCjZwzZw5PP11QlTA5OZnAwMAKn08IYQYrKxj+Hvz6OHSbWKlT6XQ6ugaqgKQs3i72fDaxB79EXOKFX45w8EIS98Y14udG7fFq1QOrW+eaNlvHEuxdVb7GmT/VbJ6yAhRNMy2oMOSfFC9Sd9N0FZzERqgaLaYm/ZZl61tqhk2LAQXBCYB7U+g2Qd3++Dfs+VzlqJQXoCTHqqAGoPPY0o/T6aD1rSp4OPNn1QUoORnqPYJKNrZ3LdaGwapo3OmNEqDUMWYP8djZ2dG6dWt69OjBvHnz6NKlCwsWLCjx2N69Vdfp6dMqi9vPz4/4+KJLphse+/n5lXpNe3t748whw00IUY2a9YbH9pQ806WK6HQ67unWhA1PDWBA28ZczHWn1+X/Y+TF+zmSUsW9JsUZpxuXUVV2z5fwZhAc+an88xl6UIpPs3b2LggCt5f8e9UsCScKejsGv1j6cT0fUPeRa8uu1gtweJUaHgrsA54tyj7WEOxUZS2SPV+q6eLugdDzwTLasKnq2iCqRKXroOj1erKyskrcFxERAYC/v/pLJzQ0lMOHD5OQkGA8Jjw8HDc3N+MwkRBCFObn7sDiB3oxb2QnXOxtiIhJ5O6P/+bFX46QlFGBcvsVYagqe34HZCTeuH/fEpXgmpWk6saUlauSnVZQVK6kMv+hM1UC6+mNEFfJhQo3v66CieA7oWmP0o/zaa8CDi1P9XiU5eBKdd9lXPnXbzlQvZfLJ1TdF0vLTFLLBAAMfL7k/KiWA1Ry99VT9WM5gQbErABlzpw5/PXXX5w7d47Dhw8zZ84ctmzZwoQJEzhz5gyvvvoq+/bt49y5c/z6669MnjyZW265hc6dOwMwdOhQQkJCmDRpEgcPHmT9+vXMnTuXmTNnYm9vWuKdEKLh0el0jL+pGZueGcBdXQLQa7Bk53kGv7eFH/ddMK/UfkV4tlAF7rQ8NW21sMM/wG+zCh4nHFPJp6W5sFeVgXdrqurMlHStkBFqe8eHFW/zxf35ybY6uHVu+ccbelH2LwF9XsnHxB2GhKMqJ6fDPeWf07FRwbpHxT83S9jxsaoi7N0WOpcSMDm4Q+BNalt6UeoUswKUhIQEJk+eTLt27Rg8eDB79+5l/fr13HbbbdjZ2bFx40aGDh1KcHAwzzzzDKNGjeK3334zvt7a2po1a9ZgbW1NaGgoEydOZPLkyUXqpgghRGl83Rz4aHw3lj3Um1aNnbmSms0zqw4y9vNdppXZr4ySFg888Tv8NAPQ1PCCISdj3+LSz1Na/klhfZ9Q90d+rHgvyp/56yt1GWdaDZCQEeDgoWZHlfZFbug9aTdMBR+mqKohlqSLsOMjtX3r3LKnZbfKz38586dl21CeXx+HLwerWVvCbJWug1ITpA6KECI7V89Xf5/lo02nychRf/Hb2VjR2MWexq72eOffN3axI8jLmW7NPGjh7YyuojNjzu+ARflfzM+dUUXIlo9VCy52Hgf3LISYXeoYW2d4NrJowqbB4jtVAuzw96HXtNKvt+QutdiezkpVur35WWjc1rS2Rm2DJXeClS08/o+aHm6KdXNg16fQ7g4Yv6Lovrxc+CBEVRYev1IFKaa4sA++ulXVJ/n3WbC2Ne115flpBhz6Tk3TfmBt2cnJF/fDl4PAzhVmR1muDWUx/LyAKmR3uxQjBfO+vy1YCUgIIaqPnY0Vjw5szYiuTXj1t2OsO6qKwV1MzOBiYsl1Nzyd7egW6EH3oEZ0a+ZBl6YeONub+Guw6U2qhyHjukpg3fq2Ck7a3w0jPlGznZqFquGGKyfV0I9h2MQgN1utjgwQVM46RPcshN+fhZNr1Rfxoe/V1ONbngPfMnL2Cq9H02Oq6cGJ4fhdn6rZSsmX1IKJBme3qODEycu0qcgGAV1VUJdxXb33snqOTHVhn/pMQC3wWF7Q6d9VtTv9KsTsgeb9Kt+G8hhmFoFawqDXNFXdVphMAhQhRJ3WxMORzyb1ICM7jyupWVxOzeJySpbaTlG3yLgUDl1M4lpaNptOJLDphErUt7bS0b2ZBwPb+XBrsA/Bfq6l97BY26gv5iM/FAQArW9TheIMwws6nVqTZsNclctRPECJPagWBXRspGqglMW9Kdy/Ei5FqMTbE2vg6E/q1v5uVTPFt8ONCxyeXKfyXGwKLfhoqsbtVHn489vV6soDZxfsM8wG6nifeT0QVtbQ6lY1XHVmU+UDFE1T1WEBuoyHJt1NaIOVasPhVSr5uKoDlOjdKqCzslHB0cV/VOXjsd9W7XXrGQlQhBD1gqOdNYGeTgR6ljwFOTtXz9FLSeyPTmR/9HX2n79ObFIme89dZ++567yzPhJ/dwcGtvNhULvG3NTCEzsbK3TojH+g27Qeis2R/LLtzW9WXzjFy8N3GQ8bX1YLG8YeUosBGkQb1t8JVV+apgjoqha+izusApVjv6jkV0O1WSdv1WvTuK2635//JdjnYXAtvXxDqXo8kB+gfKMCHCtryExW+TYAXcqofVKa1kNUgHJ6o2kJu2U5uloNpdk6weAXzGvD4VUqSBpSxpRrS9j6prrvMl7NylrYV/17nd9pmR6kBkICFCFEg2BnY0W3Zo3o1qwR01D1O2KupbPl5GW2nEhg+5krxCZlsmJPNCv2RJd4Dhes+MXOnyvWjflG+zchf1+kW6AHnQM9cDEMFTl7q3oxx35WX/LD3y04wXlD/ZMKfEn5dYIx30D8Mdg+H85tVxVS069A9JWC4AfA3h36zSr1VGUKuRvWeqpznwqHdrerL9fcDBUABZjQY1Fcq1vV/aUISLtSUD3XXDmZsDE/uOg3q+gQlKltiD0IqQllr+RdGTF7VTKuzhpufkbNyuo+WSVOb/gvPLTJMhWCGwAJUIQQDVagpxOT+gQxqU8QmTl57Dp7lc0nEvgzMoGYazfmsaTixODs/IAjMoXfIyMB9X3T1seVroEedAn0IDToPloc+1nljdz2iipjr9cXFGgLqsQQg28IjPxCbWelqvL7V04W3BJjVLl3U2fZFGdjD13vh50fw75FKkApXPukIl+urn5qHaD4w3Bms2mraZdk16eQGK1K6Pd93LzXuviAX2eIO6QCCFPquFSEIfeky/iCQnYD/6Nyki7uUz1J5qy63YBJgCKEEICDrTUD2/kwsJ0PL2kaWbl69JqGpoEGBduaxpnLaRyIvs6BmEQiohO5mJhBZHwKkfEpfPdPDDrgL3sfArMS+GHpx+g7jaePSxzNMhPV0EThYZ/KsHdRQ0CGhRQtpccDKkA5tQGid6lZRwCdxlT8nK0HqwDl9MaKBSipCbAtvyjbkBfBzrlibYg7pKY8V0WAcmEfnA7P7z0pWJ4FV1/o9yRsfk0N/wXfCbYOlr9+PSMBihBCFKPT6XCwtS51f48gO3oEFfRQJKRkEhGdyIGYRI5cTOLQhSRWZg/kOdvvaXbuB8ac7MBE63Bes4Vzjh1IjUunQ4Bbxac8VzXv1irH5tw2WDVVPdf8ZvCoxBporYeooakzm1Rvkqk5OAZ/vgbZKRDQreKBUush8PcHFW9Def56W913HnPjjJ3QmWrRxqRo2P0Z9H/SsteuhyRAEUKISvJxdWBoBz+GdlBJqZqmcSm6FdqiH7jJKpKRgan0jlfDQauvNmPBR3/TtJEjwzr6cXtHf7oGemBtVcuClR5TVYCSkr82T2V7HAJ7g50LpF1WPSn+XUx/bdxhlc8DcPubFQ8smt6kaqGkX4W4gyrYsZRLB9QMKp2VmgpenJ0TDP4/+PkR2PYedJsEzl6Wu349JAGKEEJYmE6no0lQK1V99uRa3m99CH3mOUgBXVAoDjFWXLiewZfbovhyWxR21lY083KihbdzkVurxi40dq2hZUDa31VQO8TGUU1trgwbO7U6c+QfKjfH1ADFOK1YU3VgmvWxQBt+h1MbLRugbM3vPek0uvR6J53Hwa6Faphp65twxzuWu349JJVkhRCiqkSuhRXjVGXZnDRVF+P5GDKwZ+vJBP44HMefJxJIzcot9RRdAz24t1sT7uzsj5dLNQcrG19SQyKdxxYk5lbGyfWwfIz6HB7ZaVpl3KM/w6opYG0Pj+2FRkGVa8M/i2DNk+DTAR7ZblrSr6bB3q8gNxPaDlNDYIXFHoTPbwF0MHNP2e/r7Fb45m71GTy6C7zbVObd1DnmfH9LgCKEEFUlLxfmdywYJmnSE6YXXZMmT69xKTGDc1fTiLpScDt3JY3oa+no839DW1vpuKWNN/d0a8JtIb442VVDB3hOJhz+XvWmVHRWUHHLxsCp9Wql40k/lx0gpF2FT25SU6lv+Tfc+t/KXz/jOrzbDvKyYMYW03pRTm+EpaMKHnu3VcsBtLsDmvaE7yerQnod74P7vi7/fMvHquGgpr3g/u9vLLZX0zRNzTgrr9pxBUiAIoQQtcWfr6kCa6Cmxg59zeSXJqRksuZgLD9HXOTQhSTj80521nRu6p4/q0jNMMrTNPQa6IAh7X2Y1r8ljnalJ/rWmGtn4ZM+KkAYvaTsVZF/eFBNy23cHv61VU2BtgTDeXtNL1qnpjQrJ6gAxK0ppMap1agNnBurvBp0MHO3qsZbniun4ItBKunXsyWM/870dZaqw/5v4dfHVJ7MiI8temoJUIQQora4fg4W5OdbjFsBwXdU6DRnLqfyy4GL/Bxxiehr6eUe7+tmz7ND2zGye9Pal4C7+Q1VL8StKTy2p+Qpw8d/g+8mqim7D200raS9qU5vgqUjwcEdnjlZ9pTfpIuqF0zTw6O7wc1fFbCL/EPdZyWr4zqMhNGLTG9D/DFYMVbVdbF3hzGLC4rJ1aTr52FhPxU83fZKxQv+lUICFCGEqE02vaJmooz5BmwdK3UqTdOIiEkk+lo61lY6rHQ6rHTk3+u4nJrFx3+eNi6YGOLvxn+Ht6df6wpWb60KORlq6CYxGvo/fWPp+fRr8ElvSEsoeX9l6fNgfmdVLfe+/0HHUaUfu3meSmgN6g8P/F50X262WhYg7pDqbTB3qCb1sgrCYnapQGzYW3DTdPPfj6Xo9So/5tw2COwDD/yhljqwIAlQhBCiAcvMyWPJjnN8vPk0KZlqOGJQu8Y8G9aOYD+32tGjcuJ3WHk/WNnmJ4sWSjz9cbrKfWkcDP/6y3JDO4UZht5aDYZJP5V8TF4OzO+kcohGfV01FWBzs+C3WQWLMd40A8LmFSxAWZ12fw5r/62KCT78d5WsviwBihBCCK6lZfPhplMs3XWe3PxsWysdNHa1x9fNAR9XB3zd1Hanpu7c0qZx9QUvmgbLRqvKq60Gw8QfVcLsiT9g5XhVT2TaRmjao2quf+0sfNgN0MFTR9Tq0cUZhpmcvOHp4zcuDGkpmqaK2G18GdDUUM/oJeBQjd9vV07DZ/3Vmkt3vFtlPTnmfH9LHRQhhKinPJ3teOnuDkzp25y3151gw7F48vQa8clZxCdnAUlFjg9wd2Bsr2aM7RWIn3sVl2LX6dSQxqdbVWXXE2vUGkVrnlT7+z5RdcEJqOTUoP5w/m/Ve1FScbW9+TNyuk+quuAE1GfR/ynwagM/TVdrBa0Yr4K26iiJn5cLPz+sgpOWg6DXQ1V/TRNID4oQQjQQeXqNq6lZ+QFKJvEpmcQnZ3HxegabTsSTmJ4DqF6WW4N9mdC7Gbe0reJelU2vwrZ3wT1QTbs9+pOaxvuvbVX/5RyxXFV2bdQCnjhQdMrz1TPwUXdAB7MioFHzqm2LwcX98M0IlXzbbrjKWzJ3uEevh8TzEH8E4o5ATrrKkSltptC292HTy2DvBo/uLLk3yUJkiEcIIYRZMnPyWHckjuV7otkTdc34fBMPR24L8aVfa2/6tPTE1cHWshfOTlcJs0kx6rHOCh7cAIG9LHudEq+dBu+2hexUmPoHNC+0yvSGubDjI2h9G0z8oerbUti5v+HbkWoqdteJaqpvWfVicrPUasmX9quAJP6omoVThE4lAw/4d9Gp0PFH4fMBoM+BexaqlayrkAQoQgghKux0Qgor9sTw4/4Lxl4VUMXiugZ60K+1N/1be9M10AM7GwssuHfsV/h+kto2s1ZMpf3yGBz4FrpOgHs+Vc/lZML77SHjGoxfCe2GVV97DE78rvJfNL0a7hr6asnHnd0Kvz8NV08Xfd7aTiUZ+3VSxeki/8jfoYOOI1XhO8+W8OWtam2kdnfAuOWmVdatBAlQhBBCVFpmTh5bIhP4+/QVtp++StSVtCL7XextGNC2MbeF+DKonQ/uThXsXdE0WDcHki+qkvqVnIptluhd8L8wNXPl2ZNg7woHv4PVM1SdlicPWXyqrckOLIVfZqrtIS8XXQE5NUH18hz6Tj128VWrKPt1Bt+OqoS+daF/j9iDar2gE2vyn9CBbwc1DOToqYrMufhU+VuSAEUIIYTFXbiezvbTV/j79FV2nL7C1bRs4z4bKx03tfDkthBfbgvxpWkjpxpsqRk0DT7uqXog7v5YJcR+HaZqkwyaCwNKSJ6tTts/hPD/U9t3f6SGfPYvgY0vQmYSoFMzbm6dqwrPlSf2kCqSZwxUKL+irwVJgCKEEKJK6fUahy4mEX4sjvBj8ZyMTy2yP8jLiY5N3OmUf+sY4F7xHpaqZkgSDewDd74PC/uqxfyeOgqufjXdOgh/UU1D1lmpRQ7jD6vn/TrDXfOhSQVmO8Udhl2fgVdLuPkZS7a2TBKgCCGEqFbnrqQRfiye8GPx/HP+mnGRw8KaeTrRIcCNAA9HY/0VQ00WXzcHXOxrqPJFcix8EKLyPVrdqqb5hoxQM2hqA02DXx9XuTIAdq6qx6TXQzVT0K0SJEARQghRY5LSczh0MZHDF5M4cjGJwxeTiLmWUe7rGjnZ0rGJe5Gel6aNHNFVceImoIrGndpQ8HjyL2rF5doiL1cN62Qlw8A54BZQ0y2qEAlQhBBC1CqJ6dkcuZjMibhkElLy67AkZ5KQkkVCchapWbklvs7DyZaOAe50CHAjJMCNEH83Wng7Y2NtgdlDhR39GVZNUdtereGxf6p8RktDJJVkhRBC1CoeTnb0b+NN/zYlL1qYlpXLmcupRXpdIuNSSEzP4e/TV/j79BXjsfY2VrTzcyXE342OTdwZ2sEXH9dKFnVrN0zNZsm4Bj0ekOCkFpAeFCGEELVSVm4eJ+NU0HI8Npljsckcj00mPTuvyHFWOujfpjEjuzVhaAdfnOwq+Lf3id9V/sltr4Cdc5FdUVfScLG3obFrFSxc2IDIEI8QQoh6Sa/XiL6WbgxW/j59hQPRicb9TnbW3N7Bj3u7N6FvK+9Kl+nPzMnjvQ2RfPV3FLZWVoztFcgjA1sR4FGNtVrqEQlQhBBCNBjnrqSx+sBFfo64yPmr6cbn7ayt8HW3x9/NEX8PB/zcHfB3cyDAw5HeLb1wdyx72vPRS0k8/d1BIuOLlo23tdYxumcgjw5sVXfqvdQSEqAIIYRocDRNY390IqsPXGDNodgiZfqLc7C14o5O/oy/qRk9gxoVmSmUp9f4bOsZ5m88SU6ehreLHW+O7IyLgw0LNp5i59mrgCpOd1+Ppswc1JpATwlUTCEBihBCiAYtN09PXHImcUmZxCZlEpuUQWySehwZn8LZywVl+1v7uDCuVyD3dmtCalYuT39/kH3nrwMQ1sGXN+7thJdLQe7JnqhrLNh0ku2nVaBibaXjX7e05MkhbS2zNlE9JgGKEEIIUQpN0zgQk8jKPdH8djCWjByVdGtrrcPaSkdmjh4XexteursDo7o3KbUOyz/nrrFg0ym2nVIzjNr7uzF/bFfa+blW23upayRAEUIIIUyQkpnDbwdjWbk3mkMXkgDo3cKTd0d3MXnYZu3hWP6z+jDX03Ows7bi2bC2TOvfstIJuvWRBChCCCGEmY5eSuLi9QyGtPfFyszgIiElkzk/HmbTiQQAbmrhyXtmBDkNhQQoQgghRDXTNI3v9sbw6ppjpGXn4WxnzdND29G3lRetGrtIfgoSoAghhBA1JvpqOs+simDvuevG52ytdbRq7EJ7fzfa+7sS7OdGpybuNHK2q8GWVj8JUIQQQogalKfX+GbnOdYejuN4XDIpmSWvNdTcy4mugR7q1qwR7f1dsbexrubWVp8qC1AWLlzIwoULOXfuHAAdOnTghRdeYNiwYQBkZmbyzDPPsHLlSrKysggLC+PTTz/F19fXeI7o6GgeeeQRNm/ejIuLC1OmTGHevHnY2JhemlgCFCGEEHWFpmlcTMzgeGwKx2PVgonHLiVzrlBROQM7ayvaB7gR7OtKG18X2vi60tbXBT83h+pZ1bmKVVmA8ttvv2FtbU2bNm3QNI0lS5bwzjvvcODAATp06MAjjzzC77//zuLFi3F3d+exxx7DysqK7du3A5CXl0fXrl3x8/PjnXfeITY2lsmTJzN9+nTeeOONKnmDQgghRG2UmJ5NREwiB2OSiIi5TkRMItdLKS7nam9Da18XgvMXSQwJcKe9v2vF1x2qIdU6xOPp6ck777zDfffdR+PGjVm+fDn33XcfACdOnKB9+/bs3LmTPn36sHbtWu68804uXbpk7FX57LPPmD17NpcvX8bOzrSxOAlQhBBC1DeaptYZOnwxiZPxqZyKT+FUQipRV9LI09/4VW2lgxbeznQIcKdDgBudm3rQuak7zva1N2gx5/u7wu8iLy+PVatWkZaWRmhoKPv27SMnJ4chQ4YYjwkODqZZs2bGAGXnzp106tSpyJBPWFgYjzzyCEePHqVbt24lXisrK4usrKwib1AIIYSoT3Q6HUFezgR5FV1JOTtXT9SVNE7Gp3AiLpmjl9TtckoWZy6nceZyGr8evASooKWtr2uhvBYP2vi41smaLGYHKIcPHyY0NJTMzExcXFxYvXo1ISEhREREYGdnh4eHR5HjfX19iYuLAyAuLq5IcGLYb9hXmnnz5vHyyy+b21QhhBCizrOzsaKdnyvt/Fy5q0uA8fmElEyOXlL5LEcvJRERncilpExOxKVwIi6FlXtjAHC2s6ZHc096t1C3zk096sSUZ7MDlHbt2hEREUFSUhI//PADU6ZMYevWrVXRNqM5c+bw9NNPGx8nJycTGBhYpdcUQgghajMfVwd82jkwqJ2P8bmE5EwOxCQSEZNIRHQihy4kkpadx18nL/PXycsA2NtY0b1ZI3q39KRDgDtNPBxp0six3NWdq5vZAYqdnR2tW7cGoEePHuzdu5cFCxYwduxYsrOzSUxMLNKLEh8fj5+fHwB+fn7s2bOnyPni4+ON+0pjb2+Pvb19qfuFEEIIAT5uDoR18COsg/pOzdNrnIhLZk/UNePtalo2O89eNa7KbOBqb0NAfrDSxMOR0FZe3NHJvybeBlCJHBQDvV5PVlYWPXr0wNbWlk2bNjFq1CgAIiMjiY6OJjQ0FIDQ0FBef/11EhIS8PFREV94eDhubm6EhIRUtilCCCGEKMTaSpefROvOA/1aoGkaZy6nsjs/WDlzOZVLiZlcS8smJSuXyPgUIuNTAMjVa3UnQJkzZw7Dhg2jWbNmpKSksHz5crZs2cL69etxd3dn2rRpPP3003h6euLm5sbjjz9OaGgoffr0AWDo0KGEhIQwadIk3n77beLi4pg7dy4zZ86UHhIhhBCiiul0Olr7uNLax5UJvYOMz6dn53IpMYML1zO4mJjBpcQMugY2qsGWmhmgJCQkMHnyZGJjY3F3d6dz586sX7+e2267DYAPPvgAKysrRo0aVaRQm4G1tTVr1qzhkUceITQ0FGdnZ6ZMmcIrr7xi2XclhBBCCJM52dkYA5faQkrdCyGEEKJamPP9XfvnGQkhhBCiwZEARQghhBC1jgQoQgghhKh1JEARQgghRK0jAYoQQgghah0JUIQQQghR60iAIoQQQohaRwIUIYQQQtQ6EqAIIYQQotaRAEUIIYQQtY4EKEIIIYSodSRAEUIIIUStY9ZqxrWFYX3D5OTkGm6JEEIIIUxl+N42ZZ3iOhmgpKSkABAYGFjDLRFCCCGEuVJSUnB3dy/zGJ1mShhTy+j1ei5duoSrqys6nc6i505OTiYwMJCYmJhyl4Kuz+RzUORzKCCfhSKfgyKfQwH5LBRTPgdN00hJSSEgIAArq7KzTOpkD4qVlRVNmzat0mu4ubk16B80A/kcFPkcCshnocjnoMjnUEA+C6W8z6G8nhMDSZIVQgghRK0jAYoQQgghah0JUIqxt7fnxRdfxN7evqabUqPkc1Dkcyggn4Uin4Min0MB+SwUS38OdTJJVgghhBD1m/SgCCGEEKLWkQBFCCGEELWOBChCCCGEqHUkQBFCCCFErSMBSiGffPIJzZs3x8HBgd69e7Nnz56ablKV++uvv7jrrrsICAhAp9Px888/F9mvaRovvPAC/v7+ODo6MmTIEE6dOlUzja1C8+bNo1evXri6uuLj48M999xDZGRkkWMyMzOZOXMmXl5euLi4MGrUKOLj42uoxVVj4cKFdO7c2VhoKTQ0lLVr1xr3N4TPoCRvvvkmOp2OJ5980vhcQ/ksXnrpJXQ6XZFbcHCwcX9D+RwALl68yMSJE/Hy8sLR0ZFOnTrxzz//GPc3hN+XzZs3v+HnQafTMXPmTMCyPw8SoOT77rvvePrpp3nxxRfZv38/Xbp0ISwsjISEhJpuWpVKS0ujS5cufPLJJyXuf/vtt/nwww/57LPP2L17N87OzoSFhZGZmVnNLa1aW7duZebMmezatYvw8HBycnIYOnQoaWlpxmOeeuopfvvtN1atWsXWrVu5dOkSI0eOrMFWW17Tpk1588032bdvH//88w+33norI0aM4OjRo0DD+AyK27t3L59//jmdO3cu8nxD+iw6dOhAbGys8fb3338b9zWUz+H69ev069cPW1tb1q5dy7Fjx3jvvfdo1KiR8ZiG8Pty7969RX4WwsPDARg9ejRg4Z8HTWiapmk33XSTNnPmTOPjvLw8LSAgQJs3b14Ntqp6Adrq1auNj/V6vebn56e98847xucSExM1e3t7bcWKFTXQwuqTkJCgAdrWrVs1TVPv29bWVlu1apXxmOPHj2uAtnPnzppqZrVo1KiR9tVXXzXIzyAlJUVr06aNFh4erg0YMECbNWuWpmkN6+fhxRdf1Lp06VLivob0OcyePVvr379/qfsb6u/LWbNmaa1atdL0er3Ffx6kBwXIzs5m3759DBkyxPiclZUVQ4YMYefOnTXYspoVFRVFXFxckc/F3d2d3r171/vPJSkpCQBPT08A9u3bR05OTpHPIjg4mGbNmtXbzyIvL4+VK1eSlpZGaGhog/wMZs6cyfDhw4u8Z2h4Pw+nTp0iICCAli1bMmHCBKKjo4GG9Tn8+uuv9OzZk9GjR+Pj40O3bt348ssvjfsb4u/L7Oxsli5dyoMPPohOp7P4z4MEKMCVK1fIy8vD19e3yPO+vr7ExcXVUKtqnuG9N7TPRa/X8+STT9KvXz86duwIqM/Czs4ODw+PIsfWx8/i8OHDuLi4YG9vz8MPP8zq1asJCQlpUJ8BwMqVK9m/fz/z5s27YV9D+ix69+7N4sWLWbduHQsXLiQqKoqbb76ZlJSUBvU5nD17loULF9KmTRvWr1/PI488whNPPMGSJUuAhvn78ueffyYxMZGpU6cClv9/USdXMxaiKs2cOZMjR44UGWdvSNq1a0dERARJSUn88MMPTJkyha1bt9Z0s6pVTEwMs2bNIjw8HAcHh5puTo0aNmyYcbtz58707t2boKAgvv/+exwdHWuwZdVLr9fTs2dP3njjDQC6devGkSNH+Oyzz5gyZUoNt65mfP311wwbNoyAgIAqOb/0oADe3t5YW1vfkGkcHx+Pn59fDbWq5hnee0P6XB577DHWrFnD5s2badq0qfF5Pz8/srOzSUxMLHJ8ffws7OzsaN26NT169GDevHl06dKFBQsWNKjPYN++fSQkJNC9e3dsbGywsbFh69atfPjhh9jY2ODr69tgPoviPDw8aNu2LadPn25QPxP+/v6EhIQUea59+/bG4a6G9vvy/PnzbNy4kYceesj4nKV/HiRAQf1C7tGjB5s2bTI+p9fr2bRpE6GhoTXYsprVokUL/Pz8inwuycnJ7N69u959Lpqm8dhjj7F69Wr+/PNPWrRoUWR/jx49sLW1LfJZREZGEh0dXe8+i+L0ej1ZWVkN6jMYPHgwhw8fJiIiwnjr2bMnEyZMMG43lM+iuNTUVM6cOYO/v3+D+pno16/fDaUHTp48SVBQENCwfl8CLFq0CB8fH4YPH258zuI/DxZM5q3TVq5cqdnb22uLFy/Wjh07ps2YMUPz8PDQ4uLiarppVSolJUU7cOCAduDAAQ3Q3n//fe3AgQPa+fPnNU3TtDfffFPz8PDQfvnlF+3QoUPaiBEjtBYtWmgZGRk13HLLeuSRRzR3d3dty5YtWmxsrPGWnp5uPObhhx/WmjVrpv35/+3bsYrqQBTG8REkgXSCIiLE1sJaSB1fwCqlYGlrYRpLn8DOxkafwEqLVQtBxMpOFFIKvoCVfLe4IHvv7jaL4kD+P0h1pjg5DMNHyHx8aL/fKwgCBUHwxq6fL45jrddrJUmiw+GgOI6VyWS0WCwkpWMGP/l8i0dKzyy63a5Wq5WSJNFms1Gj0VA+n9f1epWUnjnsdjtls1kNBgOdTidNp1N5nqfJZPJYk5bz8n6/y/d99Xq9L7Vn7gcCyifD4VC+78txHNXrdW2323e39HLL5VLGmC9Pq9WS9PfqXL/fV7FYlOu6CsNQx+PxvU2/wHczMMZoPB4/1txuN3U6HeVyOXmep2azqcvl8r6mX6DdbqtSqchxHBUKBYVh+AgnUjpm8JP/A0paZhFFkUqlkhzHUblcVhRFOp/Pj3pa5iBJs9lMtVpNruuqWq1qNBr9U0/LeTmfz2WM+fbdnrkfMpL0yy88AAAAL8E/KAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABY5w+jwG1oTPmO7QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label=f'Best training    loss: {min(train_losses):.0f}');\n",
    "plt.plot(val_losses, label=f'Best validation loss: {min(val_losses):.0f}');\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
